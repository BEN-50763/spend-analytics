{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"  \n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "gpt3_model = \"ft:gpt-3.5-turbo-0125:personal::9TsbbInd\"\n",
    "\n",
    "items_file_path = r\"C:\\Users\\bened\\OneDrive\\Documents\\Businesses\\Relationship Predicting\\Tesco Clubcards\\4 - Processed Data Files\\all_items.xlsx\"\n",
    "category_file_path = r\"C:\\Users\\bened\\OneDrive\\Documents\\Businesses\\Relationship Predicting\\Tesco Clubcards\\2 - Training Data\\Categorised Fine Tuning.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.read_excel(items_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gpt(item):\n",
    "\n",
    "    # Prompting fine tuned 3.5 model\n",
    "    completion = client.chat.completions.create(\n",
    "        model=gpt3_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Using only the categories included in your fine-tuning training dataset, categorise and tag the item based on the product's nature. Max 6 Tags.\"},\n",
    "            {\"role\": \"user\", \"content\": item}\n",
    "        ],\n",
    "        #max_tokens=150,\n",
    "        temperature=0.1,  # Lower temperature for more deterministic responses\n",
    "        top_p=0.2,#Probability selection of next token (0 for less diverse, 1 for max diversity)\n",
    "        frequency_penalty=-1,  # To reduce repetition (-2 no penalty, 2 avoids repetition)\n",
    "        presence_penalty=0,  # To encourage variety in mentioning new topics (-2 sticks to old topics, 2 gets new ones)\n",
    "        stop=[\"\\n\", \"<|endoftext|>\"]  # Stop at end of message or when the model thinks it's the end of the text\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def parse_item_description(description):\n",
    "    # Regular expression pattern to keep only alphanumerics, spaces, and slashes\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9 /,&\\s-]')\n",
    "    \n",
    "    # Split the string into components based on semicolons\n",
    "    parts = description.split(';')\n",
    "    \n",
    "    # Initialize dictionary to hold the parsed data\n",
    "    parsed_data = {}\n",
    "    \n",
    "    # Process each part of the split description\n",
    "    for part in parts:\n",
    "        # Split each part into a key and value\n",
    "        key, value = part.split(':')\n",
    "        key = pattern.sub('', key.strip())\n",
    "        value = pattern.sub('', value.strip())\n",
    "        \n",
    "        # Handle the 'Tags' differently since they are a list of values\n",
    "        if not key == 'Category':\n",
    "            # Split the tags by commas, strip spaces, and remove unwanted punctuation\n",
    "            parsed_data[key] = [pattern.sub('', tag.strip()) for tag in value.split(',')]\n",
    "        else:\n",
    "            # Assign the value to the corresponding key in the dictionary\n",
    "            parsed_data[key] = value\n",
    "    \n",
    "    return parsed_data['Category'], parsed_data['Flavours'], parsed_data['Tags']\n",
    "\n",
    "\n",
    "def create_data_dict(item, category, flavours, tags):\n",
    "    if not isinstance(tags, list) or not isinstance(flavours, list):\n",
    "        raise ValueError(\"Tags and flavours must be lists.\")\n",
    "\n",
    "    # Prepare the data dictionary with basic fields\n",
    "    data = {'Item Name': item, 'Category': category}\n",
    "\n",
    "    # Add flavours to the data dictionary\n",
    "    for i in range(1, len(flavours) + 1):\n",
    "        data[f'Flavour{i}'] = flavours[i-1]\n",
    "    \n",
    "    # Add tags to the data dictionary\n",
    "    for i in range(1, len(tags) + 1):\n",
    "        data[f'Tag{i}'] = tags[i-1]\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:   5%|▍         | 87/1871 [00:59<18:16,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:   5%|▍         | 88/1871 [01:02<39:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:   6%|▌         | 112/1871 [01:21<26:43,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:   6%|▌         | 113/1871 [01:24<41:17,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  30%|███       | 570/1871 [07:41<12:38,  1.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  31%|███       | 571/1871 [07:44<27:33,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  36%|███▋      | 681/1871 [08:57<15:21,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  36%|███▋      | 682/1871 [09:00<26:27,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  44%|████▍     | 828/1871 [10:32<12:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  44%|████▍     | 829/1871 [10:34<18:59,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  45%|████▌     | 844/1871 [10:45<13:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  45%|████▌     | 845/1871 [10:47<20:45,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  51%|█████     | 956/1871 [12:00<09:44,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  51%|█████     | 957/1871 [12:03<19:36,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  52%|█████▏    | 969/1871 [12:11<09:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  52%|█████▏    | 970/1871 [12:13<15:56,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  60%|█████▉    | 1114/1871 [13:45<07:15,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  61%|██████    | 1141/1871 [14:03<08:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  61%|██████    | 1142/1871 [14:05<14:32,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  70%|██████▉   | 1308/1871 [15:49<06:29,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  70%|██████▉   | 1309/1871 [15:51<11:07,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  71%|███████▏  | 1334/1871 [16:08<06:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  71%|███████▏  | 1335/1871 [16:09<05:54,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  80%|███████▉  | 1495/1871 [17:57<03:54,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  80%|███████▉  | 1496/1871 [18:00<08:04,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  81%|████████  | 1510/1871 [18:08<03:23,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  81%|████████  | 1511/1871 [18:10<05:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  95%|█████████▌| 1780/1871 [21:19<00:50,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1/3...\n",
      "Retrying 2/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items:  95%|█████████▌| 1781/1871 [21:21<01:38,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Categorising Items: 100%|██████████| 1871/1871 [22:20<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "categorised_list = []\n",
    "\n",
    "# Iterate over each item in items_df[\"name\"] with a progress bar\n",
    "for item in tqdm(items_df[\"name\"], desc=\"Categorising Items\"):\n",
    "    retries = 0\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            # Prompt fine-tuned model with item to get categorization\n",
    "            completion_string = prompt_gpt(item)\n",
    "\n",
    "            # Clean and split category output\n",
    "            category, flavours, tags = parse_item_description(completion_string)\n",
    "\n",
    "            # Insert parsed data into the DataFrame\n",
    "            categorised_list.append(create_data_dict(item, category, flavours, tags))\n",
    "\n",
    "            break  # Exit the retry loop if successful\n",
    "\n",
    "        except:\n",
    "            retries += 1\n",
    "            if retries < 3:\n",
    "                print(f\"Retrying {retries}/3...\")\n",
    "            else:\n",
    "                print(\"Skipping\")\n",
    "                break\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "categorised_df = pd.DataFrame(categorised_list)\n",
    "\n",
    "# Create datetime string to save data with\n",
    "datetimenow = datetime.now().strftime('%d%m%y_%H%M')\n",
    "\n",
    "categorised_df.to_excel(rf\"C:\\Users\\bened\\OneDrive\\Documents\\Businesses\\Relationship Predicting\\Tesco Clubcards\\4 - Processed Data Files\\Categorisations\\categorised_items_{datetimenow}.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Flavour1</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>Tag6</th>\n",
       "      <th>Flavour2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hellmann's Light Mayonnaise Squeezy 650Ml</td>\n",
       "      <td>Condiments And Dressings</td>\n",
       "      <td>Savoury</td>\n",
       "      <td>Low Calorie Option</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Express Tesco Egg Custard Tart 2 Pack</td>\n",
       "      <td>Other Desserts</td>\n",
       "      <td>Sweet</td>\n",
       "      <td>On The Go Food Or Drink</td>\n",
       "      <td>Low Nutritional Value</td>\n",
       "      <td>Animal Produce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesco Loose Red Peppers(C)</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Savoury</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Health Food Or Drink</td>\n",
       "      <td>Cooking Or Baking Ingredient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tesco Sweetheart Cabbage (C)</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Health Food Or Drink</td>\n",
       "      <td>Cooking Or Baking Ingredient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesco Carrot 500G (C)</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Savoury</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>Health Food Or Drink</td>\n",
       "      <td>Cooking Or Baking Ingredient</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>Tunnocks Milk Chocolate Caramel Wafer 240G</td>\n",
       "      <td>Bars And Biscuits</td>\n",
       "      <td>Sweet</td>\n",
       "      <td>Low Nutritional Value</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Low Nutritional Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>COSTA EXPRESS    LARGE</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Takeaway Food Or Drink</td>\n",
       "      <td>Low Nutritional Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>Snickers The Big One 100G (C)</td>\n",
       "      <td>Bars And Biscuits</td>\n",
       "      <td>Sweet</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>Low Nutritional Value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>Andrex Toilet Tissue 4 Roll White</td>\n",
       "      <td>Uncategorised</td>\n",
       "      <td>Non Food Item</td>\n",
       "      <td>Untagged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>Tesco Chocolate Eclair 4 Pack</td>\n",
       "      <td>Mints And Chewing Gum</td>\n",
       "      <td>Sweet</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Item Name                  Category  \\\n",
       "0      Hellmann's Light Mayonnaise Squeezy 650Ml  Condiments And Dressings   \n",
       "1          Express Tesco Egg Custard Tart 2 Pack            Other Desserts   \n",
       "2                     Tesco Loose Red Peppers(C)                Vegetables   \n",
       "3                   Tesco Sweetheart Cabbage (C)                Vegetables   \n",
       "4                          Tesco Carrot 500G (C)                Vegetables   \n",
       "...                                          ...                       ...   \n",
       "1852  Tunnocks Milk Chocolate Caramel Wafer 240G         Bars And Biscuits   \n",
       "1853                     COSTA EXPRESS    LARGE                     Coffee   \n",
       "1854               Snickers The Big One 100G (C)         Bars And Biscuits   \n",
       "1855           Andrex Toilet Tissue 4 Roll White             Uncategorised   \n",
       "1856               Tesco Chocolate Eclair 4 Pack     Mints And Chewing Gum   \n",
       "\n",
       "           Flavour1                     Tag1                   Tag2  \\\n",
       "0           Savoury       Low Calorie Option                  Fresh   \n",
       "1             Sweet  On The Go Food Or Drink  Low Nutritional Value   \n",
       "2           Savoury                    Fresh   Health Food Or Drink   \n",
       "3           Neutral                    Fresh   Health Food Or Drink   \n",
       "4           Savoury                    Fresh   Health Food Or Drink   \n",
       "...             ...                      ...                    ...   \n",
       "1852          Sweet    Low Nutritional Value              Chocolate   \n",
       "1853        Neutral   Takeaway Food Or Drink  Low Nutritional Value   \n",
       "1854          Sweet                Chocolate  Low Nutritional Value   \n",
       "1855  Non Food Item                 Untagged                    NaN   \n",
       "1856          Sweet                                             NaN   \n",
       "\n",
       "                              Tag3 Tag4 Tag5 Tag6 Flavour2  \n",
       "0                              NaN  NaN  NaN  NaN      NaN  \n",
       "1                   Animal Produce  NaN  NaN  NaN      NaN  \n",
       "2     Cooking Or Baking Ingredient  NaN  NaN  NaN      NaN  \n",
       "3     Cooking Or Baking Ingredient  NaN  NaN  NaN      NaN  \n",
       "4     Cooking Or Baking Ingredient  NaN  NaN  NaN      NaN  \n",
       "...                            ...  ...  ...  ...      ...  \n",
       "1852         Low Nutritional Value  NaN  NaN  NaN      NaN  \n",
       "1853                           NaN  NaN  NaN  NaN      NaN  \n",
       "1854                           NaN  NaN  NaN  NaN      NaN  \n",
       "1855                           NaN  NaN  NaN  NaN      NaN  \n",
       "1856                           NaN  NaN  NaN  NaN      NaN  \n",
       "\n",
       "[1857 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
