{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Correcting and completing the mock data creation with all necessary details\n",
    "mock_data_corrected = {\n",
    "    \"name\": [\n",
    "        \"Hellmann's Light Mayonnaise Squeezy 650Ml\", \"Express Tesco Egg Custard Tart 2 Pack\",\n",
    "        \"Tesco Loose Red Peppers(C)\", \"Yorkie Raisin & Biscuit Chocolate Bar 44g\",\n",
    "        \"San Pellegrino Sparkling Natural Mineral Water...\", \"Tesco Plant Chef Roasted Vegetable & Pesto Wrap\",\n",
    "        \"Coca-Cola Classic 2L\", \"Walkers Classic Variety Multipack Crisps 22 X 25G\",\n",
    "        \"Tesco British Whole Milk 3.408L\", \"Cadbury Dairy Milk Chocolate Bar 360G\",\n",
    "        \"Heinz Baked Beans 415g\", \"Warburtons Toastie White Bread\", \n",
    "        \"Lurpak Slightly Salted Butter 250g\", \"Kellogg's Corn Flakes 720g\",\n",
    "        \"McVitie's Digestive Biscuits 400g\", \"PG Tips Original 240 Tea Bags\",\n",
    "        \"Birds Eye 2 Chicken Shop Sizzler Fillet Burgers\", \"Fairy Original Washing Up Liquid 780ml\",\n",
    "        \"Andrex Classic Clean Toilet Tissue 9 Rolls\", \"Ariel Allin1 Pods Washing Capsules 36 Washes\"\n",
    "    ],\n",
    "    \"quantity\": [1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1],\n",
    "    \"channel\": [\"IN_STORE\"]*20,\n",
    "    \"price\": [3.1, 0.95, 0.65, 0.55, 0.92, 1.93, 2.50, 3.00, 1.45, 2.99, 0.85, 1.20, 2.25, 2.75, 1.50, 6.00, 3.50, 1.75, 4.50, 9.99],\n",
    "    \"timeStamp\": [\n",
    "        \"2024-01-26 17:30:00\", \"2024-01-26 17:32:00\",\n",
    "        \"2024-01-22 09:15:00\", \"2024-01-18 18:45:00\",\n",
    "        \"2024-01-18 18:47:00\", \"2024-01-17 12:30:00\",\n",
    "        \"2024-01-26 17:31:00\", \"2024-01-22 09:16:00\",\n",
    "        \"2024-01-19 11:00:00\", \"2024-01-17 12:31:00\",\n",
    "        \"2024-01-25 17:30:00\", \"2024-01-23 09:15:00\",\n",
    "        \"2024-01-21 18:45:00\", \"2024-01-20 12:30:00\",\n",
    "        \"2024-01-25 17:32:00\", \"2024-01-23 09:17:00\",\n",
    "        \"2024-01-21 18:46:00\", \"2024-01-20 12:32:00\",\n",
    "        \"2024-01-24 12:30:00\", \"2024-01-22 18:45:00\"\n",
    "    ],\n",
    "    \"customer_email\": [\n",
    "        \"benedict.s@hotmail.co.uk\", \"benedict.s@hotmail.co.uk\",\n",
    "        \"alex.j@example.com\", \"alex.j@example.com\",\n",
    "        \"chris.t@example.net\", \"chris.t@example.net\",\n",
    "        \"jane.d@example.com\", \"jane.d@example.com\",\n",
    "        \"dave.h@example.org\", \"dave.h@example.org\",\n",
    "        \"emily.f@example.com\", \"emily.f@example.com\",\n",
    "        \"frank.g@example.com\", \"frank.g@example.com\",\n",
    "        \"grace.h@example.com\", \"grace.h@example.com\",\n",
    "        \"harry.i@example.com\", \"harry.i@example.com\",\n",
    "        \"irene.j@example.com\", \"irene.j@example.com\"\n",
    "    ],\n",
    "    \"basketValueGross\": [4.05, 4.05, 17.34, 3.4, 3.4, 4.65, 5.00, 3.00, 4.35, 2.99, 5.10, 6.40, 4.75, 8.25, 3.00, 6.00, 7.00, 6.25, 8.50, 19.98],\n",
    "    \"purchaseType\": [\"IN_STORE\"]*20,\n",
    "    \"overallBasketSavings\": [0.9, 0.9, 0.3, 1.6, 1.6, np.nan, 0.5, 0, 0.55, 0.3, 0.4, 0.2, 0.5, 0.75, np.nan, 0.5, 0.3, 0.4, 0.6, 1.0],\n",
    "    \"storeId\": [5599, 5599, 5599, 6485, 6485, 5599, 5599, 5599, 6485, 6485, 5599, 5599, 6485, 6485, 5599, 5599, 6485, 6485, 5599, 6485],\n",
    "    \"storeAddress\": [\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"226-228 Commercial Rd, Whitechapel\",\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"125 Tooley Street\",\n",
    "        \"125 Tooley Street\", \"226-228 Commercial Rd, Whitechapel\",\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"226-228 Commercial Rd, Whitechapel\",\n",
    "        \"125 Tooley Street\", \"125 Tooley Street\",\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"226-228 Commercial Rd, Whitechapel\",\n",
    "        \"125 Tooley Street\", \"125 Tooley Street\",\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"226-228 Commercial Rd, Whitechapel\",\n",
    "        \"125 Tooley Street\", \"125 Tooley Street\",\n",
    "        \"226-228 Commercial Rd, Whitechapel\", \"125 Tooley Street\"\n",
    "    ],\n",
    "    \"storeName\": [\n",
    "        \"Commercial Rd Express\", \"Commercial Rd Express\",\n",
    "        \"Commercial Rd Express\", \"Tooley Street Express\",\n",
    "        \"Tooley Street Express\", \"Commercial Rd Express\",\n",
    "        \"Commercial Rd Express\", \"Commercial Rd Express\",\n",
    "        \"Tooley Street Express\", \"Tooley Street Express\",\n",
    "        \"Commercial Rd Express\", \"Commercial Rd Express\",\n",
    "        \"Tooley Street Express\", \"Tooley Street Express\",\n",
    "        \"Commercial Rd Express\", \"Commercial Rd Express\",\n",
    "        \"Tooley Street Express\", \"Tooley Street Express\",\n",
    "        \"Commercial Rd Express\", \"Tooley Street Express\"\n",
    "    ],\n",
    "    \"storeFormat\": [\"Express\"]*20,\n",
    "    \"type\": [\"Amex\"]*20,\n",
    "    \"amount\": [4.05, 4.05, 17.34, 3.4, 3.4, 4.65, 5.00, 3.00, 4.35, 2.99, 5.10, 6.40, 4.75, 8.25, 3.00, 6.00, 7.00, 6.25, 8.50, 19.98]\n",
    "}\n",
    "\n",
    "# Convert the corrected dictionary to a DataFrame\n",
    "mock_df_corrected = pd.DataFrame(mock_data_corrected)\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "mock_df_corrected['timeStamp'] = pd.to_datetime(mock_df_corrected['timeStamp'])\n",
    "\n",
    "# Extract time-based features\n",
    "mock_df_corrected['minute'] = mock_df_corrected['timeStamp'].dt.minute\n",
    "mock_df_corrected['hour'] = mock_df_corrected['timeStamp'].dt.hour\n",
    "mock_df_corrected['weekday'] = mock_df_corrected['timeStamp'].dt.weekday  # Monday=0, Sunday=6\n",
    "mock_df_corrected['day_of_month'] = mock_df_corrected['timeStamp'].dt.day\n",
    "\n",
    "# Now, you can drop the 'timeStamp' column to avoid dtype issues in TPOT\n",
    "mock_df_corrected.drop(['timeStamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendship_info = {\n",
    "    \"benedict.s@hotmail.co.uk\": [\"jane.d@example.com\", \"emily.f@example.com\"],  # Similar shopping times\n",
    "    \"alex.j@example.com\": [\"frank.g@example.com\", \"grace.h@example.com\"],  # Similar shopping times\n",
    "    \"chris.t@example.net\": [\"harry.i@example.com\"],  # Similar shopping times\n",
    "    \"jane.d@example.com\": [\"benedict.s@hotmail.co.uk\", \"emily.f@example.com\"],  # Similar shopping times\n",
    "    \"dave.h@example.org\": [\"irene.j@example.com\"],  # Similar shopping times\n",
    "    \"emily.f@example.com\": [\"benedict.s@hotmail.co.uk\", \"jane.d@example.com\"],  # Similar shopping times\n",
    "    \"frank.g@example.com\": [\"alex.j@example.com\"],  # Similar shopping times\n",
    "    \"grace.h@example.com\": [\"alex.j@example.com\"],  # Similar shopping times\n",
    "    \"harry.i@example.com\": [\"chris.t@example.net\"],  # Similar shopping times\n",
    "    \"irene.j@example.com\": []}\n",
    "\n",
    "# Extract unique email addresses (individuals) from the mock dataset\n",
    "individuals = mock_df_corrected['customer_email'].unique()\n",
    "\n",
    "# Initialize a DataFrame with zeros, using individuals as both rows and columns\n",
    "friendship_matrix = pd.DataFrame(0, index=individuals, columns=individuals)\n",
    "\n",
    "# Populate the matrix based on the friendship_info dictionary\n",
    "for person, friends in friendship_info.items():\n",
    "    for friend in friends:\n",
    "        friendship_matrix.loc[person, friend] = 1\n",
    "        friendship_matrix.loc[friend, person] = 1  # Friendship is mutual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mock_df_corrected is our transaction dataset\n",
    "features = mock_df_corrected.drop(['customer_email'], axis=1)  # Excluding email for feature encoding\n",
    "features_encoded = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\AppData\\Local\\Temp\\ipykernel_38248\\4208845645.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  individual_features = features_with_email.groupby('customer_email').mean()\n"
     ]
    }
   ],
   "source": [
    "# Assuming `features_encoded` is your encoded transaction data\n",
    "# Let's first ensure the customer email is included for aggregation\n",
    "mock_df_corrected['customer_email'] = mock_df_corrected['customer_email'].astype('category')\n",
    "features_with_email = pd.concat([mock_df_corrected['customer_email'], features_encoded], axis=1)\n",
    "\n",
    "# Aggregate features by customer email\n",
    "individual_features = features_with_email.groupby('customer_email').mean()\n",
    "\n",
    "# Ensure the index is consistent for later operations\n",
    "individual_features = individual_features.reindex(friendship_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for i, email_i in enumerate(friendship_matrix.index):\n",
    "    for j, email_j in enumerate(friendship_matrix.columns):\n",
    "        if i < j:  # Avoid duplicate pairs and self-pairing\n",
    "            # Combine features of both individuals in the pair\n",
    "            features_pair = pd.concat([individual_features.loc[email_i], individual_features.loc[email_j]], axis=0).to_list()\n",
    "            X_train_list.append(features_pair)\n",
    "            # Corresponding friendship status\n",
    "            y_train_list.append(friendship_matrix.loc[email_i, email_j])\n",
    "\n",
    "# Convert lists to DataFrame and Series for X_train and y_train\n",
    "X_train = pd.DataFrame(X_train_list)\n",
    "y_train = pd.Series(y_train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bened\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              \n",
      "Generation 1 - Current best internal CV score: 0.8476190476190476\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.8476190476190476\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.8476190476190476\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.8476190476190476\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.8476190476190476\n",
      "                                                                              \n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.001, max_depth=9, min_child_weight=7, n_estimators=100, n_jobs=1, subsample=0.45, verbosity=0)\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Assuming your X_train and y_train are correctly prepared\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_train, y_train, \n",
    "                                                                            test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize TPOT classifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the TPOT model to your data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n",
    "# Optionally, export the pipeline to a Python file\n",
    "# tpot.export('tpot_best_pipeline.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Bits to add\n",
    "    # How frequently a customer buys - will have to calculate from basket data then put into customer row\n",
    "    # Weight it all to include last X sets of transactions "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
