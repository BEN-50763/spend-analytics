{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_completed_file_path = r\"C:\\Users\\bened\\OneDrive\\Documents\\Businesses\\Relationship Predicting\\Tesco Clubcards\\4 - Processed Data Files\\Categorisations\\categorised_items_270524_1951.xlsx\"\n",
    "category_file_path = r\"C:\\Users\\bened\\OneDrive\\Documents\\Businesses\\Relationship Predicting\\Tesco Clubcards\\2 - Training Data\\Categorised Fine Tuning.xlsx\"\n",
    "\n",
    "ai_completed_df = pd.read_excel(ai_completed_file_path)\n",
    "\n",
    "#Open list of categories, flavours & tags & turn into a list\n",
    "category_df = pd.read_excel(category_file_path, sheet_name=\"LLM Fine Tuning\")\n",
    "\n",
    "# Select all columns except \"Line Item\"\n",
    "columns_to_consider = category_df.drop(columns=['Line Item'])\n",
    "\n",
    "# Unstack the DataFrame, drop NaN values, and get unique values\n",
    "category_list = columns_to_consider.unstack().dropna().unique().tolist()\n",
    "\n",
    "#Get list of columns we care about \n",
    "target_list = ai_completed_df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canned fooandd\n",
      "canned and preserved goods\n"
     ]
    }
   ],
   "source": [
    "# Common substitutions dictionary\n",
    "common_subs = {\n",
    "    \"&\": \"and\",\n",
    "    \"/\": \" or \",\n",
    "    \"yogurt\": \"yoghurt\",\n",
    "    \"confectionary\": \"confectionery\",\n",
    "    \"squash\": \"cordial\",\n",
    "    \"flavor\": \"flavour\",\n",
    "    \"color\": \"colour\",\n",
    "}\n",
    "\n",
    "def apply_subs(s):\n",
    "    s = s.lower()\n",
    "    for k, v in common_subs.items():\n",
    "        s = s.replace(k, v)\n",
    "    s = re.sub(r'\\s+', ' ', s)  # Replace multiple spaces with a single space\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6676396341964741\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained Word2Vec model\n",
    "# model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def embeddings_similarity(str1, str2):\n",
    "    vec1 = np.mean([model[word] for word in str1.split() if word in model], axis=0)\n",
    "    vec2 = np.mean([model[word] for word in str2.split() if word in model], axis=0)\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "\n",
    "# Example usage\n",
    "str1 = apply_subs(\"Canned Food\")\n",
    "str2 = apply_subs(\"Canned & Preserved Goods\")\n",
    "print(embeddings_similarity(str1, str2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798123953523817\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "str1 = apply_subs(\"Canned Food\")\n",
    "str2 = apply_subs(\"Tinned Food\")\n",
    "print(embeddings_similarity(str1, str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-categorized embedding for 'Canned Food': [-0.18209839 -0.10150146 -0.13671875  0.12158203 -0.01867676  0.14855957\n",
      " -0.00268555 -0.12768555  0.10668945  0.09082031  0.00878906  0.06738281\n",
      "  0.07543945 -0.07019043 -0.22558594  0.05337524  0.00390625  0.03442383\n",
      " -0.19433594 -0.01367188  0.34960938  0.33203125  0.3828125   0.05990601\n",
      " -0.015625   -0.13232422  0.04492188  0.11682129  0.23291016  0.03036499\n",
      " -0.3388672  -0.10656738  0.21191406 -0.00732422 -0.1075058  -0.04031372\n",
      " -0.1730957  -0.10864258 -0.16516113  0.0300293  -0.09350586 -0.13134766\n",
      " -0.02270508  0.12414551 -0.09936523 -0.0032959  -0.3203125   0.11096191\n",
      "  0.0559082   0.22949219 -0.4013672  -0.14916992 -0.11791992 -0.08032227\n",
      "  0.06311035  0.02807617  0.04943848 -0.10876465  0.13220215 -0.07458496\n",
      " -0.25195312  0.09802246 -0.40039062  0.19268799  0.21142578 -0.14257812\n",
      " -0.00073242 -0.1628418   0.11108398 -0.3623047   0.02124023 -0.30371094\n",
      " -0.00524902 -0.06030273 -0.17822266 -0.20028591 -0.12036133 -0.27197266\n",
      "  0.19018555  0.02685547 -0.00341797 -0.10791016  0.4033203   0.02929688\n",
      " -0.21191406 -0.1105957  -0.31591797  0.06744385  0.10400391 -0.01123047\n",
      " -0.09387207  0.10986328  0.03839111 -0.31591797  0.26757812 -0.05389404\n",
      "  0.0534668   0.05560303 -0.01171875  0.08532715 -0.09460449  0.08068848\n",
      "  0.02001953  0.08929443  0.10554886 -0.09936523 -0.06066895 -0.17578125\n",
      " -0.24658203  0.00854492 -0.08404541 -0.14001465  0.12060547 -0.15283203\n",
      "  0.06433105  0.03067017  0.07078552 -0.04452515  0.15454102 -0.03533936\n",
      "  0.14135742 -0.03417969 -0.24761963 -0.2055664  -0.25634766 -0.07568359\n",
      " -0.19189453 -0.00097656 -0.00439453 -0.3359375  -0.09606934 -0.1574707\n",
      " -0.05664062 -0.14038086 -0.4296875   0.26245117  0.0447998  -0.3317871\n",
      "  0.20703125 -0.15625     0.12255859 -0.13208008 -0.1003418  -0.16308594\n",
      "  0.00708008 -0.18847656  0.1661377   0.33447266 -0.05175781  0.0171814\n",
      "  0.05395508  0.02017212 -0.14660645 -0.18554688 -0.06835938 -0.23168945\n",
      " -0.16186523 -0.03991699 -0.2607422  -0.06848145 -0.13496399 -0.14916992\n",
      "  0.20507812  0.26464844  0.1036377  -0.03747559 -0.06072998  0.31103516\n",
      "  0.00762558 -0.14868164 -0.37841797 -0.00634766  0.15246582 -0.07189941\n",
      " -0.35546875  0.06835938 -0.10980225 -0.09448242  0.10717773 -0.13354492\n",
      " -0.16699219 -0.33154297  0.27148438 -0.06665039 -0.30859375  0.11328125\n",
      " -0.03039551 -0.20922852 -0.13110352  0.15478516 -0.07421875  0.12939453\n",
      "  0.09347534 -0.11719513 -0.18017578  0.10571289  0.29003906 -0.48339844\n",
      " -0.02172852 -0.2055664   0.05810547 -0.25390625 -0.01269531  0.0587225\n",
      " -0.07727051  0.06420898 -0.01416016 -0.05102539  0.20117188  0.08361816\n",
      " -0.24951172 -0.0423584   0.15014648  0.4638672   0.00195312  0.19677734\n",
      " -0.00305176  0.08496094  0.17041016  0.03173828 -0.05908203  0.03686523\n",
      "  0.02246094  0.07873535  0.14160156 -0.08959961 -0.12414551  0.06738281\n",
      " -0.02832031 -0.09069824 -0.09082031  0.32910156 -0.01098633 -0.00830078\n",
      "  0.02613831 -0.34033203  0.21484375  0.16333008 -0.05181885 -0.17858887\n",
      "  0.08959961  0.1081543   0.20898438  0.06860352  0.0390625   0.1619873\n",
      " -0.02383423  0.02490234 -0.09042358 -0.04394531 -0.2265625  -0.12145996\n",
      " -0.14819336  0.13220215  0.02832031  0.11572266  0.03930664 -0.24291992\n",
      "  0.01034546  0.0456543   0.09680176  0.0723877  -0.01098633 -0.04931641\n",
      "  0.06311035 -0.22265625 -0.26904297  0.05233765  0.06884766 -0.09619141\n",
      " -0.07910156  0.19433594  0.15585327 -0.01269531 -0.04260254  0.18017578\n",
      " -0.15283203 -0.06176758  0.02246094 -0.03442383 -0.14758301  0.16381836\n",
      "  0.14501953  0.13208008 -0.11889648 -0.06884766  0.10253906  0.13232422\n",
      "  0.00830078  0.3251953  -0.09765625 -0.3408203  -0.3046875   0.31933594\n",
      "  0.1352539  -0.19238281  0.00488281 -0.11474609  0.16015625 -0.08178711]\n",
      "Similarity with 'Baby Food': 0.6694309139889137\n",
      "Similarity with 'Baked Treats': 0.44093341963235866\n",
      "Similarity with 'Baking Ingredients': 0.44060095107175123\n",
      "Similarity with 'Bars & Biscuits': 0.3515353037746761\n",
      "Similarity with 'Beer': 0.37171712408336277\n",
      "Similarity with 'Bread': 0.4373473495685295\n",
      "Similarity with 'Cakes': 0.2691326629137283\n",
      "Similarity with 'Canned & Preserved Goods': 0.7067154671411467\n",
      "Similarity with 'Cereal': 0.4683321224828314\n",
      "Similarity with 'Cheese': 0.3465787201098254\n",
      "Similarity with 'Cider': 0.17356295123290866\n",
      "Similarity with 'Coffee': 0.28710022536827373\n",
      "Similarity with 'Condiments & Dressings': 0.4715016444097456\n",
      "Similarity with 'Confectionary': 0.2346329759256054\n",
      "Similarity with 'Cooking Oils & Vinegars': 0.48134085998134823\n",
      "Similarity with 'Crisps': 0.2764663855360967\n",
      "Similarity with 'Dietary Supplements': 0.4076236499297827\n",
      "Similarity with 'Dips': 0.15489191436666738\n",
      "Similarity with 'Eggs': 0.3823786263247966\n",
      "Similarity with 'Finfish & Alternatives': 0.31260994388720087\n",
      "Similarity with 'Fizzy Pop & Cordial': 0.3823198582597467\n",
      "Similarity with 'Fruit': 0.4241125725423456\n",
      "Similarity with 'Fruit Juices & Smoothies': 0.4807070958254712\n",
      "Similarity with 'Grains & Rice': 0.41181755770712725\n",
      "Similarity with 'Herbs, Spices & Flavourings': 0.3504994816834155\n",
      "Similarity with 'Ice Cream': 0.2635952112889346\n",
      "Similarity with 'Medicine': 0.18890443581210048\n",
      "Similarity with 'Milk & Milk Drinks': 0.49391149465378925\n",
      "Similarity with 'Mints & Chewing Gum': 0.3364272193960527\n",
      "Similarity with 'Mixed Drinks & Cocktails': 0.4522809708919895\n",
      "Similarity with 'Noodles': 0.322291423524234\n",
      "Similarity with 'Nuts & Seeds': 0.36471315645573177\n",
      "Similarity with 'Other Desserts': 0.3418670697959798\n",
      "Similarity with 'Other Hot Beverages': 0.43027943186802964\n",
      "Similarity with 'Pasta': 0.40048392845093983\n",
      "Similarity with 'Pastries': 0.3186437661546342\n",
      "Similarity with 'Pet Food': 0.6484783334112629\n",
      "Similarity with 'Pickled Goods': 0.49773248050162144\n",
      "Similarity with 'Pizza': 0.33005125053746165\n",
      "Similarity with 'Poultry & Alternatives': 0.40004903361371325\n",
      "Similarity with 'Prepared & Dried Fruit': 0.5606608368495521\n",
      "Similarity with 'Prepared & Dried Vegetables': 0.5640608980004147\n",
      "Similarity with 'Prepared Sandwiches, Sushi, Pasta, Salads & Deli Food': 0.6310690243022513\n",
      "Similarity with 'Processed Meats & Alternatives': 0.4762031756236442\n",
      "Similarity with 'Ready Made Sauces & Mixes': 0.47135854845798053\n",
      "Similarity with 'Ready Made Tea & Coffee': 0.41718803627972223\n",
      "Similarity with 'Ready Meals': 0.4262630880201488\n",
      "Similarity with 'Red Meat & Alternatives': 0.45522938921607126\n",
      "Similarity with 'Shellfish & Alternatives': 0.3971967966161396\n",
      "Similarity with 'Side Dishes': 0.2720848783418548\n",
      "Similarity with 'Snacks': 0.4863720298180645\n",
      "Similarity with 'Spirits': 0.2994065332466995\n",
      "Similarity with 'Sports & Energy Drinks': 0.4093788000263401\n",
      "Similarity with 'Tea': 0.24933366515789923\n",
      "Similarity with 'Toast Spreads': 0.33992498529507653\n",
      "Similarity with 'Tofu & Other Meat Alternatives': 0.5296529841677373\n",
      "Similarity with 'Tonic & Flavoured Water': 0.410154289925448\n",
      "Similarity with 'Uncategorised': 0\n",
      "Similarity with 'Vegetables': 0.4655574157686807\n",
      "Similarity with 'Water': 0.28168024514699597\n",
      "Similarity with 'Wine': 0.34481143044591067\n",
      "Similarity with 'Yoghurt & Cream': 0.3847934058011062\n",
      "Similarity with 'Savoury': 0.33339160608265694\n",
      "Similarity with 'Sweet': 0.17326546015068045\n",
      "Similarity with 'Neutral': 0.10374379354854923\n",
      "Similarity with 'Sour': 0.2511343025580979\n",
      "Similarity with 'Spicy': 0.3458303144250723\n",
      "Similarity with 'Non Food': 0.6585253108409058\n",
      "Similarity with 'Chocolate': 0.3166037197752489\n",
      "Similarity with 'Fresh': 0.3909282221371053\n",
      "Similarity with 'On The Go Food/Drink': 0.16551130355166488\n",
      "Similarity with 'Italian Food': 0.6164653421219607\n",
      "Similarity with 'Organic/Additive Free': 0.2573976176815167\n",
      "Similarity with 'Health Food/Drink': 0.27000611418618026\n",
      "Similarity with 'Low Nutritional Value': 0.43119403012737834\n",
      "Similarity with 'Middle Eastern Food': 0.5048126432991021\n",
      "Similarity with 'Cooking/Baking Ingredient': 0.43711254350151374\n",
      "Similarity with 'Low Calorie Option': 0.3031290094516158\n",
      "Similarity with 'Alcohol Free': 0.36019699848702813\n",
      "Similarity with 'Bulk Buy': 0.2974787947344222\n",
      "Similarity with 'Economy Option': 0.17451610656994176\n",
      "Similarity with 'Microwave/Oven Ready': 0.2591629050912425\n",
      "Similarity with 'Indian Food': 0.5625101510024161\n",
      "Similarity with 'Premium': 0.23949756616231554\n",
      "Similarity with 'Vegan': 0.36145239319402866\n",
      "Similarity with 'Contains Meat': 0.4731023106241439\n",
      "Similarity with 'French Food': 0.5925094908550913\n",
      "Similarity with 'Animal Produce': 0.4912036520423225\n",
      "Similarity with 'Japanese Food': 0.6020618783014327\n",
      "Similarity with 'Eastern European Food': 0.5091740090506072\n",
      "Similarity with 'South American Food': 0.5356100914296151\n",
      "Similarity with 'British Food': 0.591814274937861\n",
      "Similarity with 'Chinese Food': 0.6022862588443352\n",
      "Similarity with 'Frozen': 0.4231777773937302\n",
      "Similarity with 'African Food': 0.5580203209194515\n",
      "Similarity with 'Mexican Food': 0.5877593017461673\n",
      "Similarity with 'Meditarranian Food': 0.7686392706722066\n",
      "Similarity with 'Thai Food': 0.5778395706169733\n",
      "Similarity with 'Contains Seafood': 0.45399890702299195\n",
      "Similarity with 'American Food': 0.6323919380277684\n",
      "Similarity with 'Mediterranean Food': 0.6105333493892464\n",
      "Similarity with 'Jamaican Food': 0.5277278655536348\n",
      "Similarity with 'Untagged': 0\n",
      "Similarity with 'Korean Food': 0.560738835153574\n",
      "Similarity with 'Halal': 0.34858545269216235\n",
      "Similarity with 'Indonesian Food': 0.5604882621185026\n",
      "Similarity with 'Kosher': 0.3968654706919519\n",
      "Similarity with 'Turkish Food': 0.5942310117842701\n",
      "Best match: Meditarranian Food with similarity score of 0.7686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Function to get word embedding, handling missing words\n",
    "def get_word_embedding(word):\n",
    "    if word in model:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Function to calculate similarity\n",
    "def embeddings_similarity(vec1, vec2):\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0  # Avoid dividing by zero\n",
    "    return 1 - cosine(vec1, vec2)\n",
    "\n",
    "# Function to find best match\n",
    "def find_best_match(mis_categorized, actual_categories):\n",
    "    max_similarity = -1\n",
    "    best_match = None\n",
    "    mis_categorized_embedding = np.mean([get_word_embedding(word) for word in mis_categorized.split()], axis=0)\n",
    "    \n",
    "    print(f\"Mis-categorized embedding for '{mis_categorized}': {mis_categorized_embedding}\")\n",
    "\n",
    "    for category in actual_categories:\n",
    "        category_embedding = np.mean([get_word_embedding(word) for word in category.split()], axis=0)\n",
    "        similarity = embeddings_similarity(mis_categorized_embedding, category_embedding)\n",
    "        print(f\"Similarity with '{category}': {similarity}\")\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_match = category\n",
    "    \n",
    "    return best_match, max_similarity\n",
    "\n",
    "# Example usage\n",
    "mis_categorized = \"Canned Food\"\n",
    "best_match, similarity_score = find_best_match(mis_categorized, category_list)\n",
    "print(f\"Best match: {best_match} with similarity score of {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: None of the words in '['Uncategorised']' were found in the model!\n",
      "Warning: None of the words in '['Untagged']' were found in the model!\n",
      "Best match: Uncategorised with similarity score of 1.0000\n"
     ]
    }
   ],
   "source": [
    "actual_category_embeddings# Function to get the mean vector of a string using Word2Vec\n",
    "def get_mean_vector(model, words):\n",
    "    words = words.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:\n",
    "        print(f\"Warning: None of the words in '{words}' were found in the model!\")\n",
    "        return np.zeros(model.vector_size)\n",
    "    mean_vector = np.mean(word_vectors, axis=0)\n",
    "    return mean_vector\n",
    "\n",
    "# Encode all actual categories\n",
    "actual_category_embeddings = [get_mean_vector(model, category) for category in category_list]\n",
    "\n",
    "def find_best_match(mis_categorized_word, actual_category_list, actual_category_embeddings):\n",
    "    # Encode the mis-categorized word\n",
    "    mis_categorized_embedding = get_mean_vector(model, mis_categorized_word)\n",
    "    if np.all(mis_categorized_embedding == 0):\n",
    "        print(f\"Warning: None of the words in '{mis_categorized_word}' were found in the model!\")\n",
    "    \n",
    "    # Compute cosine similarity between the mis-categorized word and all actual categories\n",
    "    similarities = [1 - cosine(mis_categorized_embedding, category_embedding) for category_embedding in actual_category_embeddings]\n",
    "    \n",
    "    # Find the index of the highest similarity score\n",
    "    best_match_index = np.argmax(similarities)\n",
    "    \n",
    "    # Return the category with the highest similarity score\n",
    "    return actual_category_list[best_match_index], similarities[best_match_index]\n",
    "\n",
    "# Example usage\n",
    "mis_categorized_word = \"Canned Food\"\n",
    "best_match, similarity_score = find_best_match(mis_categorized_word, category_list, actual_category_embeddings)\n",
    "print(f\"Best match: {best_match} with similarity score of {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
