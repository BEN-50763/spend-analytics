{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the folder containing the Excel files\n",
    "folder_path = './Tesco Clubcards/Split Files'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter only Excel files\n",
    "excel_files = [file for file in file_list if file.endswith('.xlsx')]\n",
    "\n",
    "# Sort the file list to ensure consistent ordering\n",
    "excel_files.sort()\n",
    "\n",
    "# Iterate through the Excel files and create DataFrames\n",
    "dataframes = {}\n",
    "for i, file in enumerate(excel_files, start=1):\n",
    "    df_name = f'df{i}'\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    dataframes[df_name] = pd.read_excel(file_path)\n",
    "\n",
    "# Now you have DataFrames df1, df2, ..., dfn containing data from your Excel files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning DataFrames to variables\n",
    "df1 = dataframes['df1']\n",
    "df2 = dataframes['df2']\n",
    "df3 = dataframes['df3']\n",
    "df4 = dataframes['df4']\n",
    "df5 = dataframes['df5']\n",
    "df6 = dataframes['df6']\n",
    "df7 = dataframes['df7']\n",
    "df8 = dataframes['df8']\n",
    "df9 = dataframes['df9']\n",
    "df10 = dataframes['df10']\n",
    "df11 = dataframes['df11']\n",
    "df12 = dataframes['df12']\n",
    "df13 = dataframes['df13']\n",
    "df14 = dataframes['df14']\n",
    "df15 = dataframes['df15']\n",
    "\n",
    "# Concatenate DataFrames vertically\n",
    "merged_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop columns where all values are \"NA\"\n",
    "merged_df = merged_df.replace(\"NA\", np.nan)  # Convert \"NA\" strings to actual NaN values\n",
    "merged_df = merged_df.dropna(axis=1, how='all')  # Drop columns with all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>channel</th>\n",
       "      <th>price</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>customer_email</th>\n",
       "      <th>basketValueGross</th>\n",
       "      <th>purchaseType</th>\n",
       "      <th>overallBasketSavings</th>\n",
       "      <th>storeId</th>\n",
       "      <th>storeAddress</th>\n",
       "      <th>basketValueNet</th>\n",
       "      <th>storeName</th>\n",
       "      <th>storeFormat</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesco Bananas Loose</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_10@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTR CHICKEN NUGGETS</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_10@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Counter Tuna Steak</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>5.93</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_10@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Counter Plaice Fillet</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_10@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesco Universal Bag For Life</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_10@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>Counter Scottish Undyed Whole Msc Kipper</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_9@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Tesco Egg Custard Tarts 4 Pack</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_9@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>Seabasss With Greek Passion Marinade</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_9@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Tesco Make Me A Cuppa</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_9@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Tesco Finest Triple Chocolate Cookie 4 Pack</td>\n",
       "      <td>1</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2022-04-10 12:55:57.409</td>\n",
       "      <td>dummy_email_9@example.com</td>\n",
       "      <td>37.97</td>\n",
       "      <td>IN_STORE</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3145</td>\n",
       "      <td>BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE</td>\n",
       "      <td>21.62</td>\n",
       "      <td>ST NEOTS EXTRA</td>\n",
       "      <td>Extra</td>\n",
       "      <td>VisaCredit</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  quantity   channel  price  \\\n",
       "0                             Tesco Bananas Loose         1  IN_STORE   0.78   \n",
       "1                             CTR CHICKEN NUGGETS         1  IN_STORE   0.30   \n",
       "2                              Counter Tuna Steak         1  IN_STORE   5.93   \n",
       "3                           Counter Plaice Fillet         1  IN_STORE   2.53   \n",
       "4                    Tesco Universal Bag For Life         1  IN_STORE   0.20   \n",
       "...                                           ...       ...       ...    ...   \n",
       "1135     Counter Scottish Undyed Whole Msc Kipper         1  IN_STORE   1.00   \n",
       "1136               Tesco Egg Custard Tarts 4 Pack         1  IN_STORE   0.85   \n",
       "1137         Seabasss With Greek Passion Marinade         1  IN_STORE   8.97   \n",
       "1138                        Tesco Make Me A Cuppa         1  IN_STORE   2.50   \n",
       "1139  Tesco Finest Triple Chocolate Cookie 4 Pack         1  IN_STORE   1.65   \n",
       "\n",
       "                   timeStamp              customer_email  basketValueGross  \\\n",
       "0    2022-04-10 12:55:57.409  dummy_email_10@example.com             37.97   \n",
       "1    2022-04-10 12:55:57.409  dummy_email_10@example.com             37.97   \n",
       "2    2022-04-10 12:55:57.409  dummy_email_10@example.com             37.97   \n",
       "3    2022-04-10 12:55:57.409  dummy_email_10@example.com             37.97   \n",
       "4    2022-04-10 12:55:57.409  dummy_email_10@example.com             37.97   \n",
       "...                      ...                         ...               ...   \n",
       "1135 2022-04-10 12:55:57.409   dummy_email_9@example.com             37.97   \n",
       "1136 2022-04-10 12:55:57.409   dummy_email_9@example.com             37.97   \n",
       "1137 2022-04-10 12:55:57.409   dummy_email_9@example.com             37.97   \n",
       "1138 2022-04-10 12:55:57.409   dummy_email_9@example.com             37.97   \n",
       "1139 2022-04-10 12:55:57.409   dummy_email_9@example.com             37.97   \n",
       "\n",
       "     purchaseType  overallBasketSavings  storeId  \\\n",
       "0        IN_STORE                  1.25     3145   \n",
       "1        IN_STORE                  1.25     3145   \n",
       "2        IN_STORE                  1.25     3145   \n",
       "3        IN_STORE                  1.25     3145   \n",
       "4        IN_STORE                  1.25     3145   \n",
       "...           ...                   ...      ...   \n",
       "1135     IN_STORE                  1.25     3145   \n",
       "1136     IN_STORE                  1.25     3145   \n",
       "1137     IN_STORE                  1.25     3145   \n",
       "1138     IN_STORE                  1.25     3145   \n",
       "1139     IN_STORE                  1.25     3145   \n",
       "\n",
       "                                         storeAddress  basketValueNet  \\\n",
       "0     BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "1     BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "2     BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "3     BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "4     BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "...                                               ...             ...   \n",
       "1135  BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "1136  BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "1137  BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "1138  BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "1139  BARFORD ROAD,ST NEOTS,HUNTINGDON,CAMBRIDGESHIRE           21.62   \n",
       "\n",
       "           storeName storeFormat        type  amount  \n",
       "0     ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "1     ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "2     ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "3     ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "4     ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "...              ...         ...         ...     ...  \n",
       "1135  ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "1136  ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "1137  ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "1138  ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "1139  ST NEOTS EXTRA       Extra  VisaCredit   21.62  \n",
       "\n",
       "[1140 rows x 16 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the corrected dictionary to a DataFrame\n",
    "mock_df_corrected = merged_df\n",
    "\n",
    "# Convert timestamps to datetime objects\n",
    "mock_df_corrected['timeStamp'] = pd.to_datetime(mock_df_corrected['timeStamp'])\n",
    "\n",
    "# Extract time-based features\n",
    "mock_df_corrected['minute'] = mock_df_corrected['timeStamp'].dt.minute\n",
    "mock_df_corrected['hour'] = mock_df_corrected['timeStamp'].dt.hour\n",
    "mock_df_corrected['weekday'] = mock_df_corrected['timeStamp'].dt.weekday  # Monday=0, Sunday=6\n",
    "mock_df_corrected['day_of_month'] = mock_df_corrected['timeStamp'].dt.day\n",
    "\n",
    "# Now, you can drop the 'timeStamp' column to avoid dtype issues in TPOT\n",
    "mock_df_corrected.drop(['timeStamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendship_info = {\n",
    "    \"dummy_email_1@example.com\": [\"dummy_email_2@example.com\", \"dummy_email_4@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_2@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_3@example.com\": [\"dummy_email_2@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\"],\n",
    "    \"dummy_email_4@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\"],\n",
    "    \"dummy_email_5@example.com\": [\"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_6@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\"],\n",
    "    \"dummy_email_6@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_7@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_4@example.com\", \"dummy_email_6@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_8@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_9@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_10@example.com\": [\"dummy_email_3@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\"],\n",
    "    \"dummy_email_11@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_12@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_13@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_14@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_14@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_3@example.com\", \"dummy_email_4@example.com\", \"dummy_email_5@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_10@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_15@example.com\"],\n",
    "    \"dummy_email_15@example.com\": [\"dummy_email_1@example.com\", \"dummy_email_2@example.com\", \"dummy_email_6@example.com\", \"dummy_email_7@example.com\", \"dummy_email_8@example.com\", \"dummy_email_9@example.com\", \"dummy_email_11@example.com\", \"dummy_email_12@example.com\", \"dummy_email_13@example.com\", \"dummy_email_14@example.com\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Extract unique email addresses (individuals) from the mock dataset\n",
    "individuals = mock_df_corrected['customer_email'].unique()\n",
    "\n",
    "# Initialize a DataFrame with zeros, using individuals as both rows and columns\n",
    "friendship_matrix = pd.DataFrame(0, index=individuals, columns=individuals)\n",
    "\n",
    "# Populate the matrix based on the friendship_info dictionary\n",
    "for person, friends in friendship_info.items():\n",
    "    for friend in friends:\n",
    "        friendship_matrix.loc[person, friend] = 1\n",
    "        friendship_matrix.loc[friend, person] = 1  # Friendship is mutual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mock_df_corrected is our transaction dataset\n",
    "features = mock_df_corrected.drop(['customer_email'], axis=1)  # Excluding email for feature encoding\n",
    "features_encoded = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\AppData\\Local\\Temp\\ipykernel_8780\\4208845645.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  individual_features = features_with_email.groupby('customer_email').mean()\n"
     ]
    }
   ],
   "source": [
    "# Assuming `features_encoded` is your encoded transaction data\n",
    "# Let's first ensure the customer email is included for aggregation\n",
    "mock_df_corrected['customer_email'] = mock_df_corrected['customer_email'].astype('category')\n",
    "features_with_email = pd.concat([mock_df_corrected['customer_email'], features_encoded], axis=1)\n",
    "\n",
    "# Aggregate features by customer email\n",
    "individual_features = features_with_email.groupby('customer_email').mean()\n",
    "\n",
    "# Ensure the index is consistent for later operations\n",
    "individual_features = individual_features.reindex(friendship_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for i, email_i in enumerate(friendship_matrix.index):\n",
    "    for j, email_j in enumerate(friendship_matrix.columns):\n",
    "        if i < j:  # Avoid duplicate pairs and self-pairing\n",
    "            # Combine features of both individuals in the pair\n",
    "            features_pair = pd.concat([individual_features.loc[email_i], individual_features.loc[email_j]], axis=0).to_list()\n",
    "            X_train_list.append(features_pair)\n",
    "            # Corresponding friendship status\n",
    "            y_train_list.append(friendship_matrix.loc[email_i, email_j])\n",
    "\n",
    "# Convert lists to DataFrame and Series for X_train and y_train\n",
    "X_train = pd.DataFrame(X_train_list)\n",
    "y_train = pd.Series(y_train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \n",
      "Generation 1 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                                 \n",
      "Generation 2 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 3 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 4 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 5 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 6 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 7 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                               \n",
      "Generation 8 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                                \n",
      "Generation 9 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                                \n",
      "Generation 10 - Current best internal CV score: 0.8803030303030303\n",
      "                                                                                \n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.001, max_depth=9, min_child_weight=7, n_estimators=100, n_jobs=1, subsample=0.45, verbosity=0)\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Assuming your X_train and y_train are correctly prepared\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_train, y_train, \n",
    "                                                                            test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize TPOT classifier with a mix of specified and default parameters\n",
    "tpot = TPOTClassifier(\n",
    "    generations=10,  # Custom: 10 generations for the optimization process.\n",
    "    population_size=100,  # Custom: 100 individuals in the population per generation.\n",
    "    verbosity=2,  # Custom: Show more detailed progress and pipeline information.\n",
    "    random_state=42,  # Custom: Ensure reproducibility of your results.\n",
    "    scoring=None,  # Default: Use TPOT's default scoring method (accuracy for classification).\n",
    "    cv=None,  # Default: TPOT will use a 5-fold cross-validation.\n",
    "    max_time_mins=None,  # Default: No maximum time limit on the optimization process.\n",
    "    early_stop=None,  # Default: No early stopping. Runs for the full number of generations.\n",
    "    config_dict=None  # Default: TPOT will use its default configuration dictionary.\n",
    ")\n",
    "\n",
    "# Fit the TPOT model to your data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(f\\nModel accruacy score: {tpot.score(X_test, y_test)}%\")\n",
    "\n",
    "# Optionally, export the pipeline to a Python file\n",
    "# tpot.export('tpot_best_pipeline.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
