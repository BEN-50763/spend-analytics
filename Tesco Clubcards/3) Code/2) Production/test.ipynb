{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'search_ddg_scrape_tesco_v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msearch_ddg_scrape_tesco_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ddg_searcher\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'search_ddg_scrape_tesco_v1'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "from search_ddg_scrape_tesco_v1 import run_ddg_searcher\n",
    "from utils import get_model\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Define delay range for human-like behavior\n",
    "min_delay = 0.5\n",
    "max_delay = 1.5\n",
    "\n",
    "# Define user agents and accept languages\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/91.0.4472.80 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\"\n",
    "]\n",
    "\n",
    "accept_languages = [\n",
    "    \"en-US,en;q=0.9\",\n",
    "    \"en-GB,en;q=0.9\",\n",
    "    \"en-CA,en;q=0.9\",\n",
    "    \"en-AU,en;q=0.9\",\n",
    "    \"en-NZ,en;q=0.9\",\n",
    "    \"en-ZA,en;q=0.9\",\n",
    "    \"en-IE,en;q=0.9\"\n",
    "]\n",
    "\n",
    "# Simulate a human-like delay between requests\n",
    "def human_like_delay():\n",
    "    time.sleep(random.uniform(min_delay, max_delay))\n",
    "\n",
    "# Use origin or previous item as referrer\n",
    "def generate_referrer(previous_item=None):\n",
    "    if previous_item is None:\n",
    "        return \"https://www.tesco.com\"\n",
    "    else:\n",
    "        return f\"https://www.tesco.com/groceries/en-GB/search?query={previous_item}\"\n",
    "\n",
    "# Use origin or previous item as referrer\n",
    "def query_tesco_api(search_item, referrer, count, session=None):\n",
    "    url = \"https://api.tesco.com/shoppingexperience\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Referer\": referrer,\n",
    "        \"Origin\": \"https://www.tesco.com\",\n",
    "        \"User-Agent\": random.choice(user_agents),\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": random.choice(accept_languages),\n",
    "        \"x-apikey\": \"TvOSZJHlEk0pjniDGQFAc9Q59WGAR4dA\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    query = \"\"\"\n",
    "    query Search($query: String!, $page: Int = 1, $count: Int = 2, $sortBy: String) {\n",
    "      search(query: $query, page: $page, count: $count, sortBy: $sortBy) {\n",
    "        pageInformation: info {\n",
    "          totalCount: total\n",
    "          pageNo: page\n",
    "          count\n",
    "          __typename\n",
    "        }\n",
    "        results {\n",
    "          node {\n",
    "            ... on ProductInterface {\n",
    "              gtin\n",
    "              title\n",
    "              brandName\n",
    "              superDepartmentName\n",
    "              departmentName\n",
    "              aisleName\n",
    "              shelfName\n",
    "              reviews {\n",
    "                stats {\n",
    "                  overallRating\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    body = [{\n",
    "        \"operationName\": \"Search\",\n",
    "        \"variables\": {\n",
    "            \"query\": search_item,\n",
    "            \"page\": 1,\n",
    "            \"count\": count,\n",
    "            \"sortBy\": \"relevance\"\n",
    "        },\n",
    "        \"extensions\": {\"mfeName\": \"unknown\"},\n",
    "        \"query\": query\n",
    "    }]\n",
    "    \n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Collect the relevant section of the response\n",
    "            response = session.post(url, headers=headers, json=body)\n",
    "            json_response = response.json()\n",
    "            data = json_response[0].get('data', {})\n",
    "            search_results = data.get('search', {})\n",
    "            return {\n",
    "                \"status\": \"Data Found\",\n",
    "                \"page_information\": search_results.get('pageInformation'),\n",
    "                \"results\": search_results.get('results', [])\n",
    "            }\n",
    "        #If this didn't work, response isn't what we've been hoping for, so try again \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                logging.error(f\"API Call Unsuccessful after {max_retries} attempts for {search_item}: {str(e)}\")\n",
    "                return {\"status\": f\"API Call Unsuccessful after {max_retries} attempts for {search_item}: {str(e)}\"}\n",
    "            #Exponential sleep if it fails\n",
    "            time.sleep((2 ** attempt) + random.random())\n",
    "\n",
    "# Function to select the item dict we want from the list\n",
    "def extract_matching_dict(results, target):\n",
    "    for item in results['results']:\n",
    "        if item['node']['title'].lower() == target.lower():\n",
    "            return item['node']\n",
    "    return None\n",
    "\n",
    "# Function to rename the keys from the tesco api\n",
    "def swap_dict_keys(input_dict):\n",
    "    key_mappings = [\n",
    "        (\"title\", \"matched_name\"),\n",
    "        (\"gtin\", \"barcode\"),\n",
    "        (\"brandName\", \"brand\"),\n",
    "        (\"superDepartmentName\", \"category_1\"),\n",
    "        (\"departmentName\", \"category_2\"),\n",
    "        (\"aisleName\", \"category_3\"),\n",
    "        (\"shelfName\", \"category_4\"),\n",
    "    ]\n",
    "\n",
    "    result = {}\n",
    "    \n",
    "    # Handle the rating separately\n",
    "    try:\n",
    "        if 'reviews' in input_dict and 'stats' in input_dict['reviews'] and 'overallRating' in input_dict['reviews']['stats']:\n",
    "            result['rating'] = input_dict['reviews']['stats']['overallRating']\n",
    "    except:\n",
    "        result['rating'] = None\n",
    "    \n",
    "    # Process other mappings\n",
    "    for new_key, old_key in key_mappings:\n",
    "        if input_dict:\n",
    "            if new_key in input_dict:\n",
    "                result[old_key] = input_dict[new_key]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to clean excess wording from item names to improve matches\n",
    "def clean_string(input_string):\n",
    "    return re.sub(r'\\(.*?\\)', '', input_string).strip().lower()\n",
    "\n",
    "# Function to find the best \n",
    "def extract_best_match(target, candidates_dicts, model):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    # If the dict isn't returned or there's no returned items at all, reflect no match\n",
    "    if not candidates_dicts or \"page_information\" not in candidates_dicts or not candidates_dicts[\"page_information\"] or \"results\" not in candidates_dicts or not candidates_dicts[\"results\"]:\n",
    "        result_dict[\"item_data\"] = None\n",
    "        result_dict[\"match_score\"] = 0.0\n",
    "        return result_dict\n",
    "\n",
    "    # Extract titles into a list\n",
    "    titles = [item['node']['title'] for item in candidates_dicts['results']]\n",
    "\n",
    "    # clean all wording\n",
    "    cleaned_target = clean_string(target)\n",
    "    cleaned_titles =  [clean_string(title) for title in titles] \n",
    "\n",
    "    # If there is a perfect name match, extract this one\n",
    "    # Swap the keys for the names we want\n",
    "    if cleaned_target in cleaned_titles:\n",
    "        matched_index = cleaned_titles.index(cleaned_target) # Find where the match occured, then find the original name of the matching item to extract its dict\n",
    "        uncleaned_match = titles[matched_index]\n",
    "        result_dict[\"item_data\"] = swap_dict_keys(extract_matching_dict(candidates_dicts, uncleaned_match))\n",
    "        result_dict[\"match_score\"] = 100.0\n",
    "        return result_dict\n",
    "    # Else lets find the best match\n",
    "    else:\n",
    "        # Encode items and target then calculate similarities\n",
    "        target_embedding = model.encode(cleaned_target, convert_to_tensor=True)\n",
    "        candidate_embeddings = model.encode(cleaned_titles, convert_to_tensor=True)\n",
    "        cosine_scores = util.pytorch_cos_sim(target_embedding, candidate_embeddings)[0]\n",
    "\n",
    "        # Collect the best match then find the product name\n",
    "        best_match_index = cosine_scores.argmax().item()\n",
    "        best_match_name = titles[best_match_index]\n",
    "\n",
    "        # Extract the dict with the best matching name\n",
    "        result_dict[\"item_data\"] = swap_dict_keys(extract_matching_dict(candidates_dicts, best_match_name))\n",
    "        result_dict[\"match_score\"] = round(cosine_scores[best_match_index].item() * 100, 1)\n",
    "\n",
    "        # Use alternate method of finding the item through ddg search if poor match found\n",
    "        if result_dict[\"match_score\"] < 95:\n",
    "            ddg_result_dict = run_ddg_searcher(target, model, clean_string, accept_languages)\n",
    "\n",
    "            # If we got a better match using ddg, use this result, but only if it returned actual results\n",
    "            if result_dict[\"match_score\"] < ddg_result_dict[\"match_score\"] and ddg_result_dict[\"item_data\"][\"rating\"]:\n",
    "                result_dict = ddg_result_dict\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Main function to run the Tesco API processing\n",
    "def run_tesco_scraper(search_items):\n",
    "    model = get_model()  # Load the model for use in the scraper\n",
    "    results = []\n",
    "    session = requests.Session()\n",
    "    previous_item = None\n",
    "\n",
    "    with tqdm(total=len(search_items), desc=f\"Scraping Tesco over {len(search_items)} products\") as pbar:\n",
    "        for item in search_items:\n",
    "            # Delay to mimic human usage\n",
    "            human_like_delay()\n",
    "            referrer = generate_referrer(previous_item)\n",
    "            all_results = query_tesco_api(item, referrer, 100, session)\n",
    "\n",
    "            # Find closest match from all items we have found & return its dict\n",
    "            result = extract_best_match(item, all_results, model)\n",
    "            # If the API gave us no results, set all to None\n",
    "            if not result or not result[\"item_data\"]:\n",
    "                results.append({\n",
    "                    'name': item,\n",
    "                    'match_score': result[\"match_score\"],\n",
    "                    'matched_name': None, 'barcode': None, 'brand': None, \n",
    "                    'category_1': None, 'category_2': None, 'category_3': None, \n",
    "                    'category_4': None, 'rating': None\n",
    "                })\n",
    "            else:\n",
    "                results.append({\n",
    "                    'name': item,\n",
    "                    'match_score': result[\"match_score\"],\n",
    "                    **{f'{k}': v for k, v in result[\"item_data\"].items() if k != 'status'}\n",
    "                })\n",
    "            # Update old item so we update the referer\n",
    "            previous_item = item\n",
    "            pbar.update(1)  # Increment progress bar by 1 per item\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "## Edit method so we scrape everything then post-process to get the info (takes more storage, but more robust method)\n",
    "## Improve matching section to use a trained ML model for it \n",
    "## Add something to handle very low % matches \n",
    "## Also only search DDG with low matches as it slows things down having to do it every time < 100% - currently let to 95%\n",
    "## Bug testing \n",
    "## Add robustness, eg picks back up if no internet; can distingusih between API error codes (re run for some)\n",
    "## Ensure these are always re-run: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
    "## Sometimes two items at tesco have the same name. Find method of choosing which to use - possibly include price or other clubcard data we have\n",
    "## Remove funky accept languages & headers with module curl-cffi\n",
    "## Fix error \"'NoneType' object has no attribute 'string'â–ˆ\" - occurs when item is out of stock maybe? seems to find item, but not get results, so must have different API for those items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
