{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data written to training_data.jsonl\n",
      "Uploaded training file. File ID: file-Lh1LR57UpSVd8idNbxWnGp\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'FineTuningJob' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 114\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Create the fine-tuning job with the recommended hyperparameters:\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m#  - n_epochs: 4\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#  - batch_size: 16\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m#  - learning_rate_multiplier: 1.0\u001b[39;00m\n\u001b[0;32m    100\u001b[0m job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfine_tuning\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    101\u001b[0m     training_file\u001b[38;5;241m=\u001b[39mtraining_file_id,\n\u001b[0;32m    102\u001b[0m     model\u001b[38;5;241m=\u001b[39mgpt_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m     }\n\u001b[0;32m    113\u001b[0m )\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuning job created. Job ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# OPTIONAL: POLL JOB STATUS UNTIL COMPLETION\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolling fine-tuning job status...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'FineTuningJob' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------\n",
    "# SETUP\n",
    "# -------------------------------\n",
    "gpt_api_key = \"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\" \n",
    "gpt_model = \"gpt-4o-mini-2024-07-18\"  # or change to a specific fine-tunable snapshot if desired\n",
    "input_file = r\"G:\\My Drive\\Wantrepreneurialism\\Active\\spend-analytics\\Tesco Clubcards\\5 - Processed Data Files\\4) Gathered Data\\synthetic_items.csv\"\n",
    "training_jsonl_filename = \"training_data.jsonl\"\n",
    "\n",
    "# Set your API key\n",
    "client = OpenAI(api_key=gpt_api_key)\n",
    "\n",
    "# -------------------------------\n",
    "# DATA PREPARATION\n",
    "# -------------------------------\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Optional: Shuffle the data so each epoch sees a random order\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# Define the fixed system instruction (UK English)\n",
    "system_message = (\n",
    "    \"Categorise this item strictly using only the taxonomy from your training data. \"\n",
    "    \"Select the closest Level 3 category (most granular) and assign the corresponding fixed Level 2 (mid-level) and Level 1 (broad) categories. \"\n",
    "    \"Include the best matching characteristics and flavours. \"\n",
    "    \"Do not assign anything not present in your training data.\"\n",
    ")\n",
    "\n",
    "# Process each row to build a training example\n",
    "for _, row in df.iterrows():\n",
    "    # Extract item name (user message) and hierarchical levels\n",
    "    item_name = row[\"Item Name\"].strip()\n",
    "    level1 = row[\"L1\"].strip() if pd.notnull(row[\"L1\"]) else \"\"\n",
    "    level2 = row[\"L2\"].strip() if pd.notnull(row[\"L2\"]) else \"\"\n",
    "    level3 = row[\"L3\"].strip() if pd.notnull(row[\"L3\"]) else \"\"\n",
    "    \n",
    "    # Build the characteristics list (from Tag1 to Tag5)\n",
    "    characteristics = []\n",
    "    for i in range(1, 6):\n",
    "        tag = row.get(f\"Tag{i}\")\n",
    "        if pd.notnull(tag):\n",
    "            characteristics.append(str(tag).strip())\n",
    "    \n",
    "    # Build the flavours list (from Flav1 to Flav5; expect at least one)\n",
    "    flavours = []\n",
    "    for i in range(1, 6):\n",
    "        flav = row.get(f\"Flav{i}\")\n",
    "        if pd.notnull(flav):\n",
    "            flavours.append(str(flav).strip())\n",
    "    \n",
    "    # Build the conversation in the required format:\n",
    "    # - System message: fixed instruction\n",
    "    # - User message: item name only\n",
    "    # - Assistant message: expected output as a JSON string\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": item_name},\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps({\n",
    "            \"Level 3\": level3,\n",
    "            \"Level 2\": level2,\n",
    "            \"Level 1\": level1,\n",
    "            \"characteristics\": characteristics,\n",
    "            \"flavours\": flavours\n",
    "        }, ensure_ascii=False)}\n",
    "    ]\n",
    "    \n",
    "    output_list.append({\"messages\": messages})\n",
    "\n",
    "# Write the training data to a JSONL file (one JSON object per line)\n",
    "with open(training_jsonl_filename, \"w\", encoding=\"utf8\") as f:\n",
    "    for entry in output_list:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Training data written to {training_jsonl_filename}\")\n",
    "\n",
    "# -------------------------------\n",
    "# UPLOAD TRAINING FILE & LAUNCH FINE-TUNING JOB\n",
    "# -------------------------------\n",
    "# Upload the JSONL training file to OpenAI\n",
    "with open(training_jsonl_filename, \"rb\") as f:\n",
    "    file_response = client.files.create(file=f, purpose=\"fine-tune\") \n",
    "\n",
    "training_file_id = file_response.id  # Corrected to access `.id` directly\n",
    "print(\"Uploaded training file. File ID:\", training_file_id)\n",
    "\n",
    "\n",
    "# Create the fine-tuning job with the recommended hyperparameters:\n",
    "#  - n_epochs: 4\n",
    "#  - batch_size: 16\n",
    "#  - learning_rate_multiplier: 1.0\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=gpt_model,\n",
    "    method={\n",
    "        \"type\": \"supervised\",\n",
    "        \"supervised\": {\n",
    "            \"hyperparameters\": {\n",
    "                \"n_epochs\": 4,\n",
    "                \"batch_size\": 16,\n",
    "                \"learning_rate_multiplier\": 1.0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(\"Fine-tuning job created. Job ID:\", job.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching latest fine-tuning job...\n",
      "Latest fine-tuning job ID: ftjob-HcJwPftRK4zgPMu2UsVDaPh8\n",
      "Polling fine-tuning job status...\n",
      "2025-03-10 20:07:56.220970 - Job status: validating_files\n",
      "2025-03-10 20:08:26.469556 - Job status: validating_files\n",
      "2025-03-10 20:08:56.768398 - Job status: validating_files\n",
      "2025-03-10 20:09:27.061684 - Job status: validating_files\n",
      "2025-03-10 20:09:57.303237 - Job status: validating_files\n",
      "2025-03-10 20:10:27.555958 - Job status: validating_files\n",
      "2025-03-10 20:10:58.912432 - Job status: validating_files\n",
      "2025-03-10 20:11:29.338278 - Job status: validating_files\n",
      "2025-03-10 20:11:59.612319 - Job status: validating_files\n",
      "2025-03-10 20:12:29.880770 - Job status: validating_files\n",
      "2025-03-10 20:13:00.210253 - Job status: validating_files\n",
      "2025-03-10 20:13:30.462774 - Job status: validating_files\n",
      "2025-03-10 20:14:00.740708 - Job status: validating_files\n",
      "2025-03-10 20:14:31.042601 - Job status: validating_files\n",
      "2025-03-10 20:15:01.309705 - Job status: validating_files\n",
      "2025-03-10 20:15:31.545266 - Job status: validating_files\n",
      "2025-03-10 20:16:01.821383 - Job status: validating_files\n",
      "2025-03-10 20:16:32.077958 - Job status: validating_files\n",
      "2025-03-10 20:17:02.378457 - Job status: validating_files\n",
      "2025-03-10 20:17:32.626316 - Job status: validating_files\n",
      "2025-03-10 20:18:02.916206 - Job status: validating_files\n",
      "2025-03-10 20:18:33.196138 - Job status: validating_files\n",
      "2025-03-10 20:19:03.482553 - Job status: validating_files\n",
      "2025-03-10 20:19:33.787816 - Job status: validating_files\n",
      "2025-03-10 20:20:04.064858 - Job status: running\n",
      "2025-03-10 20:20:34.373998 - Job status: running\n",
      "2025-03-10 20:21:04.613171 - Job status: running\n",
      "2025-03-10 20:21:34.904484 - Job status: running\n",
      "2025-03-10 20:22:05.218930 - Job status: running\n",
      "2025-03-10 20:22:35.560686 - Job status: running\n",
      "2025-03-10 20:23:05.787320 - Job status: running\n",
      "2025-03-10 20:23:36.307104 - Job status: running\n",
      "2025-03-10 20:24:06.590304 - Job status: running\n",
      "2025-03-10 20:24:36.893420 - Job status: running\n",
      "2025-03-10 20:25:07.175984 - Job status: running\n",
      "2025-03-10 20:25:37.527112 - Job status: running\n",
      "2025-03-10 20:26:07.783833 - Job status: running\n",
      "2025-03-10 20:26:38.067438 - Job status: running\n",
      "2025-03-10 20:27:08.365283 - Job status: running\n",
      "2025-03-10 20:27:38.633953 - Job status: running\n",
      "2025-03-10 20:28:08.897178 - Job status: running\n",
      "2025-03-10 20:28:39.180793 - Job status: running\n",
      "2025-03-10 20:29:09.461447 - Job status: running\n",
      "2025-03-10 20:29:39.686379 - Job status: running\n",
      "2025-03-10 20:30:10.000104 - Job status: running\n",
      "2025-03-10 20:30:40.237733 - Job status: running\n",
      "2025-03-10 20:31:10.524490 - Job status: running\n",
      "2025-03-10 20:31:40.816905 - Job status: running\n",
      "2025-03-10 20:32:11.102446 - Job status: running\n",
      "2025-03-10 20:32:41.343189 - Job status: running\n",
      "2025-03-10 20:33:11.645649 - Job status: running\n",
      "2025-03-10 20:33:41.968376 - Job status: running\n",
      "2025-03-10 20:34:12.256114 - Job status: running\n",
      "2025-03-10 20:34:42.644172 - Job status: running\n",
      "2025-03-10 20:35:12.932914 - Job status: running\n",
      "2025-03-10 20:35:43.216856 - Job status: running\n",
      "2025-03-10 20:36:13.495750 - Job status: running\n",
      "2025-03-10 20:36:43.803482 - Job status: running\n",
      "2025-03-10 20:37:14.029942 - Job status: running\n",
      "2025-03-10 20:37:44.360488 - Job status: running\n",
      "2025-03-10 20:38:14.598506 - Job status: running\n",
      "2025-03-10 20:38:44.904160 - Job status: running\n",
      "2025-03-10 20:39:15.160162 - Job status: running\n",
      "2025-03-10 20:39:45.490127 - Job status: running\n",
      "2025-03-10 20:40:15.763132 - Job status: running\n",
      "2025-03-10 20:40:46.034560 - Job status: running\n",
      "2025-03-10 20:41:16.321506 - Job status: running\n",
      "2025-03-10 20:41:46.587876 - Job status: running\n",
      "2025-03-10 20:42:16.833550 - Job status: running\n",
      "2025-03-10 20:42:47.052563 - Job status: running\n",
      "2025-03-10 20:43:17.368710 - Job status: running\n",
      "2025-03-10 20:43:47.596610 - Job status: running\n",
      "2025-03-10 20:44:17.857961 - Job status: running\n",
      "2025-03-10 20:44:48.156660 - Job status: running\n",
      "2025-03-10 20:45:18.406990 - Job status: running\n",
      "2025-03-10 20:45:48.689960 - Job status: running\n",
      "2025-03-10 20:46:18.943302 - Job status: running\n",
      "2025-03-10 20:46:49.227367 - Job status: running\n",
      "2025-03-10 20:47:19.495786 - Job status: running\n",
      "2025-03-10 20:47:49.752315 - Job status: running\n",
      "2025-03-10 20:48:21.187631 - Job status: running\n",
      "2025-03-10 20:48:51.474658 - Job status: running\n",
      "2025-03-10 20:49:21.734615 - Job status: running\n",
      "2025-03-10 20:49:51.964262 - Job status: running\n",
      "2025-03-10 20:50:22.259537 - Job status: running\n",
      "2025-03-10 20:50:52.534680 - Job status: running\n",
      "2025-03-10 20:51:22.812582 - Job status: running\n",
      "2025-03-10 20:51:53.085808 - Job status: running\n",
      "2025-03-10 20:52:23.337698 - Job status: running\n",
      "2025-03-10 20:52:53.574555 - Job status: running\n",
      "2025-03-10 20:53:23.838771 - Job status: running\n",
      "2025-03-10 20:53:54.146737 - Job status: running\n",
      "2025-03-10 20:54:24.423668 - Job status: running\n",
      "2025-03-10 20:54:54.736137 - Job status: running\n",
      "2025-03-10 20:55:25.052521 - Job status: running\n",
      "2025-03-10 20:55:55.341733 - Job status: running\n",
      "2025-03-10 20:56:25.607839 - Job status: running\n",
      "2025-03-10 20:56:55.909051 - Job status: running\n",
      "2025-03-10 20:57:26.194671 - Job status: running\n",
      "2025-03-10 20:57:56.505743 - Job status: running\n",
      "2025-03-10 20:58:26.782060 - Job status: running\n",
      "2025-03-10 20:58:57.057704 - Job status: running\n",
      "2025-03-10 20:59:27.304457 - Job status: running\n",
      "2025-03-10 20:59:57.560051 - Job status: running\n",
      "2025-03-10 21:00:27.833272 - Job status: running\n",
      "2025-03-10 21:00:58.099652 - Job status: running\n",
      "2025-03-10 21:01:28.337687 - Job status: running\n",
      "2025-03-10 21:01:58.603275 - Job status: running\n",
      "2025-03-10 21:02:28.866877 - Job status: running\n",
      "2025-03-10 21:02:59.216041 - Job status: running\n",
      "2025-03-10 21:03:29.503432 - Job status: running\n",
      "2025-03-10 21:03:59.764743 - Job status: running\n",
      "2025-03-10 21:04:30.072294 - Job status: running\n",
      "2025-03-10 21:05:00.390777 - Job status: running\n",
      "2025-03-10 21:05:30.675712 - Job status: running\n",
      "2025-03-10 21:06:00.940740 - Job status: running\n",
      "2025-03-10 21:06:31.193035 - Job status: running\n",
      "2025-03-10 21:07:01.468104 - Job status: running\n",
      "2025-03-10 21:07:31.757620 - Job status: running\n",
      "2025-03-10 21:08:02.080333 - Job status: running\n",
      "2025-03-10 21:08:32.502619 - Job status: running\n",
      "2025-03-10 21:09:02.755235 - Job status: running\n",
      "2025-03-10 21:09:33.327450 - Job status: running\n",
      "2025-03-10 21:10:03.640956 - Job status: running\n",
      "2025-03-10 21:10:33.924916 - Job status: succeeded\n",
      "Fine-tuning completed successfully! Fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal::B9eg9Tmn\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# RETRIEVE LATEST FINE-TUNING JOB\n",
    "# -------------------------------\n",
    "print(\"Fetching latest fine-tuning job...\")\n",
    "\n",
    "try:\n",
    "    latest_job = client.fine_tuning.jobs.list(limit=1).data[0]  # Get the most recent job\n",
    "    fine_tuning_job_id = latest_job.id  # Extract job ID\n",
    "    print(f\"Latest fine-tuning job ID: {fine_tuning_job_id}\")\n",
    "except Exception as e:\n",
    "    print(\"Error retrieving latest fine-tuning job:\", e)\n",
    "    exit()\n",
    "\n",
    "# -------------------------------\n",
    "# POLLING LOOP FOR JOB STATUS\n",
    "# -------------------------------\n",
    "print(\"Polling fine-tuning job status...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "        status = current_job.status  # Correctly accessing job status\n",
    "        print(f\"{datetime.now()} - Job status: {status}\")\n",
    "\n",
    "        if status == \"succeeded\":\n",
    "            fine_tuned_model = current_job.fine_tuned_model\n",
    "            print(\"Fine-tuning completed successfully! Fine-tuned model:\", fine_tuned_model)\n",
    "            break\n",
    "        elif status in [\"failed\", \"cancelled\"]:\n",
    "            print(\"Fine-tuning job did not succeed. Status:\", status)\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving job status:\", e)\n",
    "\n",
    "    time.sleep(30)  # Wait 30 seconds before checking again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
