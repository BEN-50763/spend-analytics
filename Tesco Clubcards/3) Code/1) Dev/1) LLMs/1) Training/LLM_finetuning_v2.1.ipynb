{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data written to training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------\n",
    "# SETUP\n",
    "# -------------------------------\n",
    "gpt_api_key = \"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\" \n",
    "gpt_model = \"gpt-4o-mini-2024-07-18\"  # or change to a specific fine-tunable snapshot if desired\n",
    "input_file = r\"G:\\My Drive\\Wantrepreneurialism\\Active\\spend-analytics\\Tesco Clubcards\\2) Data\\2) Data Preparations\\synthetic_items.csv\"\n",
    "training_jsonl_filename = \"training_data.jsonl\"\n",
    "\n",
    "# Set your API key\n",
    "client = OpenAI(api_key=gpt_api_key)\n",
    "\n",
    "# -------------------------------\n",
    "# DATA PREPARATION\n",
    "# -------------------------------\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Optional: Shuffle the data so each epoch sees a random order\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "output_list = []\n",
    "\n",
    "system_message = (\n",
    "    \"Categorise this item strictly using only the taxonomy from your training data. \"\n",
    "    \"Use only pre-existing categories and never create new ones. \"\n",
    "    \"If the exact category is unclear, pick the closest valid Level 3 category (most granular) rather than inventing a new one. \"\n",
    "    \"Assign its corresponding fixed Level 2 (mid-level) and Level 1 (broad) categories. \"\n",
    "    \"Ensure characteristics and flavours are only from the predefined lists. \"\n",
    "    \"Output your answer in valid JSON with keys: category_3, category_2, category_1, characteristics, and flavours.\"\n",
    ")\n",
    "\n",
    "# Process each row to build a training example\n",
    "for _, row in df.iterrows():\n",
    "    # Extract item name (user message) and hierarchical levels\n",
    "    item_name = row[\"Item Name\"].strip()\n",
    "    level1 = row[\"L1\"].strip() if pd.notnull(row[\"L1\"]) else \"\"\n",
    "    level2 = row[\"L2\"].strip() if pd.notnull(row[\"L2\"]) else \"\"\n",
    "    level3 = row[\"L3\"].strip() if pd.notnull(row[\"L3\"]) else \"\"\n",
    "    \n",
    "    # Build the characteristics list (from Tag1 to Tag5)\n",
    "    characteristics = []\n",
    "    for i in range(1, 6):\n",
    "        tag = row.get(f\"Tag{i}\")\n",
    "        if pd.notnull(tag):\n",
    "            characteristics.append(str(tag).strip())\n",
    "    \n",
    "    # Build the flavours list (from Flav1 to Flav5; expect at least one)\n",
    "    flavours = []\n",
    "    for i in range(1, 6):\n",
    "        flav = row.get(f\"Flav{i}\")\n",
    "        if pd.notnull(flav):\n",
    "            flavours.append(str(flav).strip())\n",
    "    \n",
    "    # Build the conversation in the required format:\n",
    "    # - System message: fixed instruction\n",
    "    # - User message: item name only\n",
    "    # - Assistant message: expected output as a JSON string\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": item_name},\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps({\n",
    "            \"category_3\": level3,\n",
    "            \"category_2\": level2,\n",
    "            \"category_1\": level1,\n",
    "            \"characteristics\": characteristics,\n",
    "            \"flavours\": flavours\n",
    "        }, ensure_ascii=False)}\n",
    "    ]\n",
    "    \n",
    "    output_list.append({\"messages\": messages})\n",
    "\n",
    "# Write the training data to a JSONL file (one JSON object per line)\n",
    "with open(training_jsonl_filename, \"w\", encoding=\"utf8\") as f:\n",
    "    for entry in output_list:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Training data written to {training_jsonl_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training file. File ID: file-EaVB3mxcZKy4yxgRHPyHcU\n",
      "Fine-tuning job created. Job ID: ftjob-UIxbT5qmhYTSkfCJQltLNVOp\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# UPLOAD TRAINING FILE & LAUNCH FINE-TUNING JOB\n",
    "# -------------------------------\n",
    "# Upload the JSONL training file to OpenAI\n",
    "with open(training_jsonl_filename, \"rb\") as f:\n",
    "    file_response = client.files.create(file=f, purpose=\"fine-tune\") \n",
    "\n",
    "training_file_id = file_response.id  # Corrected to access `.id` directly\n",
    "print(\"Uploaded training file. File ID:\", training_file_id)\n",
    "\n",
    "\n",
    "# Create the fine-tuning job with the recommended hyperparameters:\n",
    "#  - n_epochs: 4\n",
    "#  - batch_size: 16\n",
    "#  - learning_rate_multiplier: 1.0\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=gpt_model,\n",
    "    method={\n",
    "        \"type\": \"supervised\",\n",
    "        \"supervised\": {\n",
    "            \"hyperparameters\": {\n",
    "                \"n_epochs\": 5,\n",
    "                \"batch_size\": 20,\n",
    "                \"learning_rate_multiplier\": 0.6\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(\"Fine-tuning job created. Job ID:\", job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching latest fine-tuning job...\n",
      "Latest fine-tuning job ID: ftjob-UIxbT5qmhYTSkfCJQltLNVOp\n",
      "Polling fine-tuning job status...\n",
      "2025-03-18 09:54:07.928383 - Job status: validating_files\n",
      "2025-03-18 09:54:38.358110 - Job status: validating_files\n",
      "2025-03-18 09:55:08.589170 - Job status: validating_files\n",
      "2025-03-18 09:55:38.870023 - Job status: validating_files\n",
      "2025-03-18 09:56:09.136998 - Job status: validating_files\n",
      "2025-03-18 09:56:39.438987 - Job status: validating_files\n",
      "2025-03-18 09:57:09.719827 - Job status: validating_files\n",
      "2025-03-18 09:57:39.969836 - Job status: validating_files\n",
      "2025-03-18 09:58:10.238560 - Job status: validating_files\n",
      "2025-03-18 09:58:40.504226 - Job status: validating_files\n",
      "2025-03-18 09:59:10.769189 - Job status: validating_files\n",
      "2025-03-18 09:59:41.049892 - Job status: validating_files\n",
      "2025-03-18 10:00:11.350096 - Job status: running\n",
      "2025-03-18 10:00:41.650408 - Job status: running\n",
      "2025-03-18 10:01:11.916395 - Job status: running\n",
      "2025-03-18 10:01:42.219917 - Job status: running\n",
      "2025-03-18 10:02:12.485285 - Job status: running\n",
      "2025-03-18 10:02:42.764776 - Job status: running\n",
      "2025-03-18 10:03:13.093687 - Job status: running\n",
      "2025-03-18 10:03:43.380205 - Job status: running\n",
      "2025-03-18 10:04:13.630368 - Job status: running\n",
      "2025-03-18 10:04:43.879349 - Job status: running\n",
      "2025-03-18 10:05:14.145945 - Job status: running\n",
      "2025-03-18 10:05:44.439385 - Job status: running\n",
      "2025-03-18 10:06:14.696340 - Job status: running\n",
      "2025-03-18 10:06:44.961154 - Job status: running\n",
      "2025-03-18 10:07:15.194020 - Job status: running\n",
      "2025-03-18 10:07:45.493655 - Job status: running\n",
      "2025-03-18 10:08:15.726402 - Job status: running\n",
      "2025-03-18 10:08:45.993242 - Job status: running\n",
      "2025-03-18 10:09:16.275590 - Job status: running\n",
      "2025-03-18 10:09:46.542022 - Job status: running\n",
      "2025-03-18 10:10:16.827045 - Job status: running\n",
      "2025-03-18 10:10:47.159826 - Job status: running\n",
      "2025-03-18 10:11:17.424877 - Job status: running\n",
      "2025-03-18 10:11:47.720659 - Job status: running\n",
      "2025-03-18 10:12:17.972659 - Job status: running\n",
      "2025-03-18 10:12:48.257672 - Job status: running\n",
      "2025-03-18 10:13:18.504823 - Job status: running\n",
      "2025-03-18 10:13:48.788969 - Job status: running\n",
      "2025-03-18 10:14:19.069158 - Job status: running\n",
      "2025-03-18 10:14:49.346662 - Job status: running\n",
      "2025-03-18 10:15:19.611262 - Job status: running\n",
      "2025-03-18 10:15:49.890477 - Job status: running\n",
      "2025-03-18 10:16:20.152741 - Job status: running\n",
      "2025-03-18 10:16:50.431761 - Job status: running\n",
      "2025-03-18 10:17:20.703468 - Job status: running\n",
      "2025-03-18 10:17:50.960084 - Job status: running\n",
      "2025-03-18 10:18:21.235835 - Job status: running\n",
      "2025-03-18 10:18:51.480558 - Job status: running\n",
      "2025-03-18 10:19:21.749246 - Job status: running\n",
      "2025-03-18 10:19:52.008656 - Job status: running\n",
      "2025-03-18 10:20:22.281638 - Job status: running\n",
      "2025-03-18 10:20:52.534370 - Job status: running\n",
      "2025-03-18 10:21:22.785935 - Job status: running\n",
      "2025-03-18 10:21:53.059845 - Job status: running\n",
      "2025-03-18 10:22:23.293668 - Job status: running\n",
      "2025-03-18 10:22:53.553053 - Job status: running\n",
      "2025-03-18 10:23:23.803430 - Job status: running\n",
      "2025-03-18 10:23:54.076694 - Job status: running\n",
      "2025-03-18 10:24:24.382860 - Job status: running\n",
      "2025-03-18 10:24:54.670775 - Job status: running\n",
      "2025-03-18 10:25:24.951871 - Job status: running\n",
      "2025-03-18 10:25:55.242049 - Job status: running\n",
      "2025-03-18 10:26:25.518024 - Job status: running\n",
      "2025-03-18 10:26:55.793942 - Job status: running\n",
      "2025-03-18 10:27:26.043365 - Job status: running\n",
      "2025-03-18 10:27:56.311428 - Job status: running\n",
      "2025-03-18 10:28:26.648039 - Job status: running\n",
      "2025-03-18 10:28:56.938297 - Job status: running\n",
      "2025-03-18 10:29:27.190989 - Job status: running\n",
      "2025-03-18 10:29:57.475505 - Job status: running\n",
      "2025-03-18 10:30:27.785549 - Job status: running\n",
      "2025-03-18 10:30:58.060671 - Job status: running\n",
      "2025-03-18 10:31:28.319801 - Job status: running\n",
      "2025-03-18 10:31:58.611874 - Job status: running\n",
      "2025-03-18 10:32:28.913953 - Job status: running\n",
      "2025-03-18 10:32:59.176800 - Job status: running\n",
      "2025-03-18 10:33:29.426990 - Job status: running\n",
      "2025-03-18 10:33:59.729996 - Job status: running\n",
      "2025-03-18 10:34:30.001418 - Job status: running\n",
      "2025-03-18 10:35:00.269870 - Job status: running\n",
      "2025-03-18 10:35:30.570118 - Job status: running\n",
      "2025-03-18 10:36:00.859129 - Job status: running\n",
      "2025-03-18 10:36:31.108301 - Job status: running\n",
      "2025-03-18 10:37:01.360676 - Job status: running\n",
      "2025-03-18 10:37:31.611453 - Job status: running\n",
      "2025-03-18 10:38:01.874828 - Job status: running\n",
      "2025-03-18 10:38:32.165830 - Job status: running\n",
      "2025-03-18 10:39:02.458658 - Job status: running\n",
      "2025-03-18 10:39:32.697498 - Job status: running\n",
      "2025-03-18 10:40:03.003094 - Job status: running\n",
      "2025-03-18 10:40:33.318190 - Job status: running\n",
      "2025-03-18 10:41:03.607740 - Job status: running\n",
      "2025-03-18 10:41:33.917835 - Job status: running\n",
      "2025-03-18 10:42:04.236273 - Job status: running\n",
      "2025-03-18 10:42:34.495597 - Job status: running\n",
      "2025-03-18 10:43:04.784551 - Job status: running\n",
      "2025-03-18 10:43:35.043561 - Job status: running\n",
      "2025-03-18 10:44:05.331338 - Job status: running\n",
      "2025-03-18 10:44:35.632838 - Job status: running\n",
      "2025-03-18 10:45:05.868583 - Job status: running\n",
      "2025-03-18 10:45:36.101863 - Job status: running\n",
      "2025-03-18 10:46:06.382507 - Job status: running\n",
      "2025-03-18 10:46:36.672527 - Job status: running\n",
      "2025-03-18 10:47:06.968337 - Job status: running\n",
      "2025-03-18 10:47:37.253481 - Job status: running\n",
      "2025-03-18 10:48:07.534238 - Job status: running\n",
      "2025-03-18 10:48:37.797513 - Job status: running\n",
      "2025-03-18 10:49:08.118087 - Job status: running\n",
      "2025-03-18 10:49:38.390948 - Job status: running\n",
      "2025-03-18 10:50:08.707284 - Job status: running\n",
      "2025-03-18 10:50:38.983060 - Job status: running\n",
      "2025-03-18 10:51:09.314196 - Job status: running\n",
      "2025-03-18 10:51:39.573467 - Job status: running\n",
      "2025-03-18 10:52:09.855101 - Job status: running\n",
      "2025-03-18 10:52:40.138375 - Job status: running\n",
      "2025-03-18 10:53:10.391556 - Job status: running\n",
      "2025-03-18 10:53:40.702888 - Job status: running\n",
      "2025-03-18 10:54:10.955787 - Job status: running\n",
      "2025-03-18 10:54:41.260244 - Job status: running\n",
      "2025-03-18 10:55:11.539343 - Job status: succeeded\n",
      "Fine-tuning completed successfully! Fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal::BCOsoAm5\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# RETRIEVE LATEST FINE-TUNING JOB\n",
    "# -------------------------------\n",
    "print(\"Fetching latest fine-tuning job...\")\n",
    "\n",
    "try:\n",
    "    latest_job = client.fine_tuning.jobs.list(limit=1).data[0]  # Get the most recent job\n",
    "    fine_tuning_job_id = latest_job.id  # Extract job ID\n",
    "    print(f\"Latest fine-tuning job ID: {fine_tuning_job_id}\")\n",
    "except Exception as e:\n",
    "    print(\"Error retrieving latest fine-tuning job:\", e)\n",
    "    exit()\n",
    "\n",
    "# -------------------------------\n",
    "# POLLING LOOP FOR JOB STATUS\n",
    "# -------------------------------\n",
    "print(\"Polling fine-tuning job status...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        current_job = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
    "        status = current_job.status  # Correctly accessing job status\n",
    "        print(f\"{datetime.now()} - Job status: {status}\")\n",
    "\n",
    "        if status == \"succeeded\":\n",
    "            fine_tuned_model = current_job.fine_tuned_model\n",
    "            print(\"Fine-tuning completed successfully! Fine-tuned model:\", fine_tuned_model)\n",
    "            break\n",
    "        elif status in [\"failed\", \"cancelled\"]:\n",
    "            print(\"Fine-tuning job did not succeed. Status:\", status)\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error retrieving job status:\", e)\n",
    "\n",
    "    time.sleep(30)  # Wait 30 seconds before checking again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
