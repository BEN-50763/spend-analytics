{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to open tesco files from people, save in new location\n",
    "# then append new items to item list\n",
    "# create UID for each\n",
    "# trigger supermarket flow (or more likely this one is called in supermarket flow which runs every 30s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Outputs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "input_folder_path = r\"G:\\My Drive\\Wantrepreneurialism\\Active\\spend-analytics\\Tesco Clubcards\\2) Data\\1) Raw data\"\n",
    "output_folder_path = r\"G:\\My Drive\\Wantrepreneurialism\\Active\\spend-analytics\\Tesco Clubcards\\2) Data\\3) Outputs\"\n",
    "all_items_path = r\"G:\\My Drive\\Wantrepreneurialism\\Active\\spend-analytics\\Tesco Clubcards\\2) Data\\2) Data Preparations\\all_items.xlsx\"\n",
    "\n",
    "# Function to process each JSON file\n",
    "def process_json_file(filepath, unique_id):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract customer profile and purchase data\n",
    "    customer_data = data.get(\"Customer Profile And Contact Data\", {})\n",
    "    purchase_data = data.get(\"Purchase\", [])\n",
    "\n",
    "    # Extract customer email\n",
    "    customer_email = customer_data.get(\"Online Account\", {}).get(\"email address\", \"Unknown\")\n",
    "\n",
    "    # Process purchase data\n",
    "    all_baskets, all_payments, all_products = [], [], []\n",
    "\n",
    "    for transactions in purchase_data:\n",
    "        for entry in transactions:\n",
    "            # Extract basket details\n",
    "            basket_details = {k: v for k, v in entry.items() if k not in [\"product\", \"paymentType\"]}\n",
    "            basket_details[\"customer_email\"] = customer_email\n",
    "\n",
    "            # Extract payment details safely\n",
    "            payment_df = pd.json_normalize(entry.get(\"paymentType\", []))\n",
    "            payment_df[\"timeStamp\"] = entry[\"timeStamp\"]\n",
    "\n",
    "            # Extract product details\n",
    "            product_df = pd.json_normalize(entry[\"product\"])\n",
    "            product_df[\"timeStamp\"] = entry[\"timeStamp\"]\n",
    "            product_df[\"customer_email\"] = customer_email\n",
    "\n",
    "            all_baskets.append(basket_details)\n",
    "            all_payments.append(payment_df)\n",
    "            all_products.append(product_df)\n",
    "\n",
    "    # Convert lists to DataFrames\n",
    "    basket_df = pd.DataFrame(all_baskets)\n",
    "    payment_df = pd.concat(all_payments, ignore_index=True) if all_payments else pd.DataFrame()\n",
    "    product_df = pd.concat(all_products, ignore_index=True) if all_products else pd.DataFrame()\n",
    "\n",
    "    # Merge basket and payment data\n",
    "    basket_df = pd.merge(basket_df, payment_df, on=\"timeStamp\", how=\"left\") if not payment_df.empty else basket_df\n",
    "\n",
    "    # Merge basket and product data\n",
    "    total_spend_df = pd.merge(product_df, basket_df, on=[\"timeStamp\", \"customer_email\"], how=\"left\")\n",
    "\n",
    "    return basket_df, product_df, total_spend_df\n",
    "\n",
    "# Process all JSON files\n",
    "for file in os.listdir(input_folder_path):\n",
    "    if file.endswith('.json'):\n",
    "        match = re.search(r'_(\\w+)\\.json$', file)  # Extract unique name\n",
    "        if match:\n",
    "            unique_id = match.group(1)\n",
    "            filepath = os.path.join(input_folder_path, file)\n",
    "            basket_df, product_df, total_spend_df = process_json_file(filepath, unique_id)\n",
    "\n",
    "            # Create output folder for each unique ID\n",
    "            unique_output_folder = os.path.join(output_folder_path, unique_id)\n",
    "            os.makedirs(unique_output_folder, exist_ok=True)\n",
    "\n",
    "            # Save outputs\n",
    "            basket_df.to_excel(os.path.join(unique_output_folder, \"DIM_basket_Tesco.xlsx\"), index=False)\n",
    "            product_df.to_excel(os.path.join(unique_output_folder, \"Tesco_transactions.xlsx\"), index=False)\n",
    "            total_spend_df.to_excel(os.path.join(unique_output_folder, \"Tesco.xlsx\"), index=False)\n",
    "\n",
    "# Ensure all_items.xlsx exists with correct columns\n",
    "if os.path.exists(all_items_path):\n",
    "    all_items_df = pd.read_excel(all_items_path)\n",
    "    if \"Product name\" not in all_items_df.columns:\n",
    "        all_items_df[\"Product name\"] = \"\"  # Add missing column\n",
    "else:\n",
    "    all_items_df = pd.DataFrame(columns=[\"UID\", \"Product name\"])  # Create empty DataFrame\n",
    "\n",
    "# Extract unique product names while preserving original case\n",
    "if \"name\" in product_df.columns:\n",
    "    new_products = product_df[\"name\"].dropna().unique()  # Preserve original case\n",
    "else:\n",
    "    new_products = []\n",
    "\n",
    "# Create a set of existing product names (case-insensitive match)\n",
    "existing_products_lower = set(all_items_df[\"Product name\"].dropna().str.lower()) if \"Product name\" in all_items_df.columns else set()\n",
    "\n",
    "# Identify new entries (case-insensitive match, original case preserved)\n",
    "new_entries = [p for p in new_products if p.lower() not in existing_products_lower]\n",
    "\n",
    "# Append new products with original case\n",
    "if new_entries:\n",
    "    start_id = all_items_df.shape[0] + 1\n",
    "    new_items_df = pd.DataFrame({\n",
    "        \"UID\": [f\"ID_{i}\" for i in range(start_id, start_id + len(new_entries))],\n",
    "        \"Product name\": new_entries  # Keeps original casing\n",
    "    })\n",
    "    all_items_df = pd.concat([all_items_df, new_items_df], ignore_index=True)\n",
    "    all_items_df.to_excel(all_items_path, index=False)\n",
    "\n",
    "print(\"Processing complete. Outputs saved in respective folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
