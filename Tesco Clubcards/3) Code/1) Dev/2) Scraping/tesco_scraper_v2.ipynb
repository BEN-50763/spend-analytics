{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bened\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\bened\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define delay range for human-like behavior\n",
    "min_delay = 0.5\n",
    "max_delay = 1.5\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('sentence_transformers').setLevel(logging.ERROR) # Turn off most logging \n",
    "\n",
    "# Define user agents and accept languages\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (iPad; CPU OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) CriOS/91.0.4472.80 Mobile/15E148 Safari/604.1\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\"\n",
    "]\n",
    "\n",
    "accept_languages = [\n",
    "    \"en-US,en;q=0.9\",\n",
    "    \"en-GB,en;q=0.9\",\n",
    "    \"en-CA,en;q=0.9\",\n",
    "    \"en-AU,en;q=0.9\",\n",
    "    \"en-NZ,en;q=0.9\",\n",
    "    \"en-ZA,en;q=0.9\",\n",
    "    \"en-IE,en;q=0.9\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a human-like delay between requests\n",
    "def human_like_delay():\n",
    "    time.sleep(random.uniform(min_delay, max_delay))\n",
    "\n",
    "# Use origin or previous item as referrer\n",
    "def generate_referrer(previous_item=None):\n",
    "    if previous_item is None:\n",
    "        return \"https://www.tesco.com\"\n",
    "    else:\n",
    "        return f\"https://www.tesco.com/groceries/en-GB/search?query={previous_item}\"\n",
    "\n",
    "# Use origin or previous item as referrer\n",
    "def query_tesco_api(search_item, referrer, count, session=None):\n",
    "    url = \"https://api.tesco.com/shoppingexperience\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Referer\": referrer,\n",
    "        \"Origin\": \"https://www.tesco.com\",\n",
    "        \"User-Agent\": random.choice(user_agents),\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": random.choice(accept_languages),\n",
    "        \"x-apikey\": \"TvOSZJHlEk0pjniDGQFAc9Q59WGAR4dA\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    query = \"\"\"\n",
    "    query Search($query: String!, $page: Int = 1, $count: Int = 2, $sortBy: String) {\n",
    "      search(query: $query, page: $page, count: $count, sortBy: $sortBy) {\n",
    "        pageInformation: info {\n",
    "          totalCount: total\n",
    "          pageNo: page\n",
    "          count\n",
    "          __typename\n",
    "        }\n",
    "        results {\n",
    "          node {\n",
    "            ... on ProductInterface {\n",
    "              gtin\n",
    "              title\n",
    "              brandName\n",
    "              superDepartmentName\n",
    "              departmentName\n",
    "              aisleName\n",
    "              shelfName\n",
    "              reviews {\n",
    "                stats {\n",
    "                  overallRating\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    body = [{\n",
    "        \"operationName\": \"Search\",\n",
    "        \"variables\": {\n",
    "            \"query\": search_item,\n",
    "            \"page\": 1,\n",
    "            \"count\": count,\n",
    "            \"sortBy\": \"relevance\"\n",
    "        },\n",
    "        \"extensions\": {\"mfeName\": \"unknown\"},\n",
    "        \"query\": query\n",
    "    }]\n",
    "    \n",
    "    if session is None:\n",
    "        session = requests.Session()\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Collect the relevant section of the response\n",
    "            response = session.post(url, headers=headers, json=body)\n",
    "            json_response = response.json()\n",
    "            data = json_response[0].get('data', {})\n",
    "            search_results = data.get('search', {})\n",
    "            return {\n",
    "                \"status\": \"Data Found\",\n",
    "                \"page_information\": search_results.get('pageInformation'),\n",
    "                \"results\": search_results.get('results', [])\n",
    "            }\n",
    "        #If this didn't work, response isn't what we've been hoping for, so try again \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Error querying item {search_item}: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\"status\": f\"API Call Unsuccessful: {str(e)}\"}\n",
    "            #Exponential sleep if it fails\n",
    "            time.sleep((2 ** attempt) + random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matching_dict(results, target):\n",
    "    for item in results['results']:\n",
    "        if item['node']['title'].lower() == target.lower():\n",
    "            return item['node']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename the keys from the tesco api\n",
    "def swap_dict_keys(input_dict):\n",
    "    key_mappings = [\n",
    "        (\"title\", \"matched_name\"),\n",
    "        (\"gtin\", \"barcode\"),\n",
    "        (\"brandName\", \"brand\"),\n",
    "        (\"superDepartmentName\", \"category_1\"),\n",
    "        (\"departmentName\", \"category_2\"),\n",
    "        (\"aisleName\", \"category_3\"),\n",
    "        (\"shelfName\", \"category_4\"),\n",
    "    ]\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Handle the rating separately\n",
    "    if 'reviews' in input_dict and 'stats' in input_dict['reviews'] and 'overallRating' in input_dict['reviews']['stats']:\n",
    "        result['rating'] = input_dict['reviews']['stats']['overallRating']\n",
    "    \n",
    "    # Process other mappings\n",
    "    for new_key, old_key in key_mappings:\n",
    "        if new_key in input_dict:\n",
    "            result[old_key] = input_dict[new_key]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best \n",
    "def extract_best_match(target, candidates_dicts):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    # Extract titles into a list\n",
    "    titles = [item['node']['title'] for item in candidates_dicts['results']]\n",
    "\n",
    "    if not candidates_dicts:\n",
    "        result_dict[\"item_data\"] = None\n",
    "        result_dict[\"match_score\"] = 0.0\n",
    "        return result_dict\n",
    "\n",
    "    # clean all wording\n",
    "    cleaned_target = re.sub(r'\\(.*?\\)', '', target).strip().lower()\n",
    "    cleaned_titles = [re.sub(r'\\(.*?\\)', '', c).strip().lower() for c in titles]\n",
    "\n",
    "    # If there is a perfect name match, extract this one\n",
    "    # Swap the keys for the names we want\n",
    "    if cleaned_target in cleaned_titles:\n",
    "        result_dict[\"item_data\"] = swap_dict_keys(extract_matching_dict(candidates_dicts, target))\n",
    "        result_dict[\"match_score\"] = 100.0\n",
    "        return result_dict\n",
    "\n",
    "    # Encode items and target then calculate similarities\n",
    "    target_embedding = model.encode(cleaned_target, convert_to_tensor=True)\n",
    "    candidate_embeddings = model.encode(cleaned_titles, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(target_embedding, candidate_embeddings)[0]\n",
    "\n",
    "    # Collect the best match then find the product name\n",
    "    best_match_index = cosine_scores.argmax().item()\n",
    "    best_match_name = titles[best_match_index]\n",
    "\n",
    "    # Extract the dict with the best matching name\n",
    "    result_dict[\"item_data\"] = swap_dict_keys(extract_matching_dict(candidates_dicts, best_match_name))\n",
    "    result_dict[\"match_score\"] = round(cosine_scores[best_match_index].item() * 100, 1)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the Tesco API processing\n",
    "def run_tesco_scraper(search_items):\n",
    "    results = []\n",
    "    session = requests.Session()\n",
    "    previous_item = None\n",
    "    \n",
    "    for item in tqdm(search_items, desc=\"Processing search items\"):\n",
    "        print(item)\n",
    "        human_like_delay()\n",
    "        referrer = generate_referrer(previous_item)\n",
    "        all_results = query_tesco_api(item, referrer, 100, session)\n",
    "\n",
    "        #Find closest match from all items we have found & return its dict\n",
    "        result = extract_best_match(item, all_results)\n",
    "        \n",
    "        results.append({\n",
    "            'name': item,\n",
    "            'match_score': result[\"match_score\"],\n",
    "            **{f'{k}': v for k, v in result[\"item_data\"].items() if k != 'status'}\n",
    "        })\n",
    "        \n",
    "        if result['item_data']:\n",
    "            previous_item = item\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"\"\n",
    "referrer = generate_referrer(None)\n",
    "candidates_dicts = query_tesco_api(item, referrer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mswap_dict_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_matching_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 16\u001b[0m, in \u001b[0;36mswap_dict_keys\u001b[1;34m(input_dict)\u001b[0m\n\u001b[0;32m     13\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Handle the rating separately\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreviews\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_dict\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverallRating\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m input_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverallRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Process other mappings\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "swap_dict_keys(extract_matching_dict(candidates_dicts, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Data Found', 'page_information': None, 'results': None}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [item['node']['title'] for item in candidates_dicts['results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesco Mini Gems Sweets 200G\n"
     ]
    }
   ],
   "source": [
    "for item in titles:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [1, 2, 3]\n",
    "\n",
    "p.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
